# 智能标签化路由系统增强需求文档

## 问题分析

根据日志文件 `logs/20250822-1649.log` 的分析，发现以下关键问题：

### 1. 标签前缀不一致性问题
- **成功案例**: `tag:qwen,vl,free` (第746行) - 正常工作，找到6个候选渠道
- **失败案例**: `tags:qwen,>20b,free` (第677行) - 路由失败，提示"No channels found"
- **失败案例**: `tags:qwen3,free` (第702行) - 路由失败，提示"No channels found"

### 2. 参数大小过滤功能缺失
- 用户期望: `tag:qwen3,>20b,free` 应该筛选出 qwen3 参数量大于 20b 的带 free 标签的大模型
- 当前状态: `>20b` 这样的参数大小过滤标签无法被正确解析和处理

### 3. 上下文大小过滤功能缺失
- 用户期望: 添加 `>10ki`, `>8ko` 这样的过滤参数，筛选掉小于 input 10k 和小于 output 8k 的大模型
- 当前状态: 系统不支持上下文大小的过滤功能

## 功能需求

### 1. 参数大小过滤功能
**目标**: 支持通过参数大小标签过滤模型

**需求规格**:
- 支持参数大小比较操作符: `>`, `<`, `>=`, `<=`, `=`
- 支持参数大小单位: `b` (billion), `m` (million), `k` (thousand)
- 解析逻辑: 从模型名称中提取参数数量，与过滤条件进行比较
- 示例:
  - `>20b` → 参数量 > 20 billion
  - `<7b` → 参数量 < 7 billion  
  - `>=1.5b` → 参数量 >= 1.5 billion
  - `=70b` → 参数量 = 70 billion

**技术实现**:
- 在 `core/json_router.py` 中添加参数大小解析逻辑
- 从模型名称中提取参数数量 (如 `qwen3-30b-a3b` → 30b)
- 实现参数大小比较和过滤功能
- 集成到现有的标签匹配系统中

### 2. 上下文大小过滤功能
**目标**: 支持通过上下文大小标签过滤模型

**需求规格**:
- 支持 input/output 上下文大小过滤
- 支持上下文大小比较操作符: `>`, `<`, `>=`, `<=`, `=`
- 支持上下文大小单位: 
  - `ki` / `ko` → k tokens (input/output)
  - `mi` / `mo` → m tokens (input/output)
  - `bi` / `bo` → b tokens (input/output)
- 解析逻辑: 从模型缓存中提取上下文大小信息，与过滤条件进行比较
- 示例:
  - `>10ki` → input context > 10k tokens
  - `<8ko` → output context < 8k tokens
  - `>=32ki` → input context >= 32k tokens
  - `<=4ko` → output context <= 4k tokens

**技术实现**:
- 在 `core/json_router.py` 中添加上下文大小解析逻辑
- 从模型缓存数据中提取 `max_input_tokens` 和 `max_output_tokens`
- 实现上下文大小比较和过滤功能
- 集成到现有的标签匹配系统中

### 3. 标签前缀一致性修复
**目标**: 确保 `tags:` 前缀与 `tag:` 前缀功能完全一致

**需求规格**:
- `tags:qwen3,free` 应该与 `tag:qwen3,free` 产生相同的结果
- 修复 `tags:` 前缀的解析逻辑，确保能正确识别和处理
- 保持向后兼容性，现有的 `tag:` 前缀继续正常工作

**技术实现**:
- 修复 `core/json_router.py` 中的标签前缀解析逻辑
- 确保 `tags:` 前缀能正确触发多标签查询模式
- 统一 `tags:` 和 `tag:` 前缀的处理逻辑

## 技术架构

### 现有架构分析
- **标签提取**: `core/json_router.py` 中的 `AUTO TAGGING` 功能
- **标签匹配**: `core/json_router.py` 中的 `TAG MATCHING` 功能  
- **内存索引**: `core/utils/memory_index.py` 中的高性能标签查询
- **模型缓存**: `core/utils/api_key_cache.py` 中的模型信息缓存

### 增强方案
1. **扩展标签解析器**: 在 `core/json_router.py` 中添加参数大小和上下文大小解析
2. **增强标签匹配**: 在标签匹配过程中集成大小过滤逻辑
3. **优化缓存结构**: 确保模型缓存中包含参数大小和上下文大小信息
4. **统一前缀处理**: 修复 `tags:` 和 `tag:` 前缀的一致性问题

## 开发计划

### Phase 1: 标签前缀一致性修复 (1-2小时)
- [ ] 修复 `tags:` 前缀解析逻辑
- [ ] 确保 `tags:` 前缀能正确触发多标签查询
- [ ] 测试 `tags:` 和 `tag:` 前缀的一致性

### Phase 2: 参数大小过滤功能 (2-3小时)
- [ ] 实现参数大小解析逻辑
- [ ] 添加参数大小比较功能
- [ ] 集成到标签匹配系统中
- [ ] 测试参数大小过滤功能

### Phase 3: 上下文大小过滤功能 (2-3小时)
- [ ] 实现上下文大小解析逻辑
- [ ] 添加上下文大小比较功能
- [ ] 集成到标签匹配系统中
- [ ] 测试上下文大小过滤功能

### Phase 4: 综合测试和优化 (1-2小时)
- [ ] 测试组合过滤功能
- [ ] 性能优化和内存使用优化
- [ ] 文档更新和示例代码

## 测试用例

### 参数大小过滤测试
1. `tag:qwen3,>20b,free` → 应该找到 qwen3-30b-a3b:free 等模型
2. `tag:llama,<7b,free` → 应该找到 llama-2-7b-chat 等模型
3. `tag:gemma,>=2b,free` → 应该找到 gemma-2-9b-it 等模型

### 上下文大小过滤测试
1. `tag:qwen3,>10ki,free` → 应该找到 input context > 10k 的 qwen3 模型
2. `tag:llama,<8ko,free` → 应该找到 output context < 8k 的 llama 模型
3. `tag:gemma,>32ki,free` → 应该找到 input context > 32k 的 gemma 模型

### 组合过滤测试
1. `tag:qwen3,>20b,>10ki,free` → 参数量>20b且input>10k的qwen3免费模型
2. `tag:llama,<7b,<8ko,free` → 参数量<7b且output<8k的llama免费模型

### 标签前缀一致性测试
1. `tags:qwen3,free` vs `tag:qwen3,free` → 结果应该一致
2. `tags:qwen,>20b,free` vs `tag:qwen,>20b,free` → 结果应该一致

## 成功标准

### 功能性标准
- [ ] `tags:` 前缀与 `tag:` 前缀功能完全一致
- [ ] 参数大小过滤功能正常工作，支持所有比较操作符和单位
- [ ] 上下文大小过滤功能正常工作，支持所有比较操作符和单位
- [ ] 组合过滤功能正常工作，可以同时使用多个过滤条件

### 性能标准
- [ ] 标签匹配性能保持在现有水平 (毫秒级响应)
- [ ] 内存使用保持在合理范围内
- [ ] 不影响现有的路由功能

### 兼容性标准
- [ ] 向后兼容现有的 `tag:` 前缀
- [ ] 不影响现有的模型发现和缓存功能
- [ ] 不影响现有的路由策略和评分系统

## 风险评估

### 技术风险
- **参数大小解析准确性**: 模型名称格式不统一可能导致解析错误
- **上下文信息完整性**: 部分模型可能缺少上下文大小信息
- **性能影响**: 新的过滤逻辑可能影响标签匹配性能

### 缓解措施
- 实现健壮的解析逻辑，处理各种模型名称格式
- 为缺少上下文信息的模型提供合理的默认值或跳过过滤
- 使用缓存和预计算优化性能

## 预期收益

### 用户体验提升
- 更精确的模型筛选能力
- 更灵活的标签组合查询
- 统一的标签前缀体验

### 系统功能增强
- 支持更细粒度的模型过滤
- 提高路由系统的智能化程度
- 为未来功能扩展奠定基础

### 开发效率提升
- 减少用户手动筛选模型的工作量
- 提供更直观的查询接口
- 降低使用复杂度