#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼‚æ­¥æ–‡ä»¶æ“ä½œå·¥å…· - ä½¿ç”¨aiofilesä¼˜åŒ–IOæ€§èƒ½
"""

import asyncio
import json
import logging
import time
from datetime import date, datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import aiofiles
import aiofiles.os
import yaml

logger = logging.getLogger(__name__)


class DateTimeEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œæ”¯æŒdatetimeå¯¹è±¡åºåˆ—åŒ–"""

    def default(self, obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        elif hasattr(obj, "__dict__"):
            # å¤„ç†åŒ…å«datetimeçš„è‡ªå®šä¹‰å¯¹è±¡
            return obj.__dict__
        return super().default(obj)


class AsyncFileManager:
    """å¼‚æ­¥æ–‡ä»¶ç®¡ç†å™¨"""

    def __init__(self):
        self._file_locks = {}  # æ–‡ä»¶é”ï¼Œé˜²æ­¢å¹¶å‘å†™å…¥å†²çª

    def _get_file_lock(self, file_path: Union[str, Path]) -> asyncio.Lock:
        """è·å–æ–‡ä»¶é”"""
        file_key = str(file_path)
        if file_key not in self._file_locks:
            self._file_locks[file_key] = asyncio.Lock()
        return self._file_locks[file_key]

    async def read_json(self, file_path: Union[str, Path], default: Any = None) -> Any:
        """å¼‚æ­¥è¯»å–JSONæ–‡ä»¶"""
        try:
            path = Path(file_path)
            if not await aiofiles.os.path.exists(path):
                logger.debug(f"JSONæ–‡ä»¶ä¸å­˜åœ¨: {path}")
                return default

            start_time = time.time()
            async with aiofiles.open(path, "r", encoding="utf-8") as f:
                content = await f.read()

            if not content.strip():
                logger.debug(f"JSONæ–‡ä»¶ä¸ºç©º: {path}")
                return default

            data = json.loads(content)
            read_time = (time.time() - start_time) * 1000
            logger.debug(
                f"ğŸ“– ASYNC READ: {path.name} ({len(content)} bytes, {read_time:.1f}ms)"
            )

            return data

        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥ {file_path}: {e}")
            return default
        except Exception as e:
            logger.error(f"å¼‚æ­¥è¯»å–JSONå¤±è´¥ {file_path}: {e}")
            return default

    async def write_json(
        self,
        file_path: Union[str, Path],
        data: Any,
        ensure_dir: bool = True,
        indent: int = 2,
    ) -> bool:
        """å¼‚æ­¥å†™å…¥JSONæ–‡ä»¶"""
        try:
            path = Path(file_path)

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            if ensure_dir:
                await aiofiles.os.makedirs(path.parent, exist_ok=True)

            # ä½¿ç”¨æ–‡ä»¶é”é˜²æ­¢å¹¶å‘å†™å…¥
            async with self._get_file_lock(path):
                start_time = time.time()

                # åºåˆ—åŒ–æ•°æ®ï¼Œä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨æ”¯æŒdatetime
                json_content = json.dumps(
                    data, indent=indent, ensure_ascii=False, cls=DateTimeEncoder
                )

                # å¼‚æ­¥å†™å…¥
                async with aiofiles.open(path, "w", encoding="utf-8") as f:
                    await f.write(json_content)

                write_time = (time.time() - start_time) * 1000
                logger.debug(
                    f"ğŸ’¾ ASYNC WRITE: {path.name} ({len(json_content)} bytes, {write_time:.1f}ms)"
                )

            return True

        except Exception as e:
            logger.error(f"å¼‚æ­¥å†™å…¥JSONå¤±è´¥ {file_path}: {e}")
            return False

    async def read_yaml(self, file_path: Union[str, Path], default: Any = None) -> Any:
        """å¼‚æ­¥è¯»å–YAMLæ–‡ä»¶"""
        try:
            path = Path(file_path)
            if not await aiofiles.os.path.exists(path):
                logger.debug(f"YAMLæ–‡ä»¶ä¸å­˜åœ¨: {path}")
                return default

            start_time = time.time()
            async with aiofiles.open(path, "r", encoding="utf-8") as f:
                content = await f.read()

            if not content.strip():
                logger.debug(f"YAMLæ–‡ä»¶ä¸ºç©º: {path}")
                return default

            data = yaml.safe_load(content)
            read_time = (time.time() - start_time) * 1000
            logger.debug(
                f"ğŸ“– ASYNC READ: {path.name} YAML ({len(content)} bytes, {read_time:.1f}ms)"
            )

            return data

        except yaml.YAMLError as e:
            logger.error(f"YAMLè§£æå¤±è´¥ {file_path}: {e}")
            return default
        except Exception as e:
            logger.error(f"å¼‚æ­¥è¯»å–YAMLå¤±è´¥ {file_path}: {e}")
            return default

    async def write_yaml(
        self, file_path: Union[str, Path], data: Any, ensure_dir: bool = True
    ) -> bool:
        """å¼‚æ­¥å†™å…¥YAMLæ–‡ä»¶"""
        try:
            path = Path(file_path)

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            if ensure_dir:
                await aiofiles.os.makedirs(path.parent, exist_ok=True)

            # ä½¿ç”¨æ–‡ä»¶é”é˜²æ­¢å¹¶å‘å†™å…¥
            async with self._get_file_lock(path):
                start_time = time.time()

                # åºåˆ—åŒ–æ•°æ®
                yaml_content = yaml.dump(
                    data, default_flow_style=False, allow_unicode=True, indent=2
                )

                # å¼‚æ­¥å†™å…¥
                async with aiofiles.open(path, "w", encoding="utf-8") as f:
                    await f.write(yaml_content)

                write_time = (time.time() - start_time) * 1000
                logger.debug(
                    f"ğŸ’¾ ASYNC WRITE: {path.name} YAML ({len(yaml_content)} bytes, {write_time:.1f}ms)"
                )

            return True

        except Exception as e:
            logger.error(f"å¼‚æ­¥å†™å…¥YAMLå¤±è´¥ {file_path}: {e}")
            return False

    async def read_text(
        self, file_path: Union[str, Path], encoding: str = "utf-8"
    ) -> Optional[str]:
        """å¼‚æ­¥è¯»å–æ–‡æœ¬æ–‡ä»¶"""
        try:
            path = Path(file_path)
            if not await aiofiles.os.path.exists(path):
                logger.debug(f"æ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {path}")
                return None

            start_time = time.time()
            async with aiofiles.open(path, "r", encoding=encoding) as f:
                content = await f.read()

            read_time = (time.time() - start_time) * 1000
            logger.debug(
                f"ğŸ“– ASYNC READ: {path.name} ({len(content)} chars, {read_time:.1f}ms)"
            )

            return content

        except Exception as e:
            logger.error(f"å¼‚æ­¥è¯»å–æ–‡æœ¬å¤±è´¥ {file_path}: {e}")
            return None

    async def write_text(
        self,
        file_path: Union[str, Path],
        content: str,
        encoding: str = "utf-8",
        ensure_dir: bool = True,
    ) -> bool:
        """å¼‚æ­¥å†™å…¥æ–‡æœ¬æ–‡ä»¶"""
        try:
            path = Path(file_path)

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            if ensure_dir:
                await aiofiles.os.makedirs(path.parent, exist_ok=True)

            # ä½¿ç”¨æ–‡ä»¶é”é˜²æ­¢å¹¶å‘å†™å…¥
            async with self._get_file_lock(path):
                start_time = time.time()

                # å¼‚æ­¥å†™å…¥
                async with aiofiles.open(path, "w", encoding=encoding) as f:
                    await f.write(content)

                write_time = (time.time() - start_time) * 1000
                logger.debug(
                    f"ğŸ’¾ ASYNC WRITE: {path.name} ({len(content)} chars, {write_time:.1f}ms)"
                )

            return True

        except Exception as e:
            logger.error(f"å¼‚æ­¥å†™å…¥æ–‡æœ¬å¤±è´¥ {file_path}: {e}")
            return False

    async def append_text(
        self,
        file_path: Union[str, Path],
        content: str,
        encoding: str = "utf-8",
        ensure_dir: bool = True,
    ) -> bool:
        """å¼‚æ­¥è¿½åŠ æ–‡æœ¬åˆ°æ–‡ä»¶"""
        try:
            path = Path(file_path)

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            if ensure_dir:
                await aiofiles.os.makedirs(path.parent, exist_ok=True)

            # ä½¿ç”¨æ–‡ä»¶é”é˜²æ­¢å¹¶å‘å†™å…¥
            async with self._get_file_lock(path):
                start_time = time.time()

                # å¼‚æ­¥è¿½åŠ 
                async with aiofiles.open(path, "a", encoding=encoding) as f:
                    await f.write(content)

                write_time = (time.time() - start_time) * 1000
                logger.debug(
                    f"â• ASYNC APPEND: {path.name} (+{len(content)} chars, {write_time:.1f}ms)"
                )

            return True

        except Exception as e:
            logger.error(f"å¼‚æ­¥è¿½åŠ æ–‡æœ¬å¤±è´¥ {file_path}: {e}")
            return False

    async def file_exists(self, file_path: Union[str, Path]) -> bool:
        """å¼‚æ­¥æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        try:
            return await aiofiles.os.path.exists(Path(file_path))
        except Exception:
            return False

    async def get_file_size(self, file_path: Union[str, Path]) -> Optional[int]:
        """å¼‚æ­¥è·å–æ–‡ä»¶å¤§å°"""
        try:
            path = Path(file_path)
            if await aiofiles.os.path.exists(path):
                stat = await aiofiles.os.stat(path)
                return stat.st_size
            return None
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
            return None

    async def remove_file(self, file_path: Union[str, Path]) -> bool:
        """å¼‚æ­¥åˆ é™¤æ–‡ä»¶"""
        try:
            path = Path(file_path)
            if await aiofiles.os.path.exists(path):
                await aiofiles.os.remove(path)
                logger.debug(f"ğŸ—‘ï¸ ASYNC DELETE: {path.name}")
                return True
            return False
        except Exception as e:
            logger.error(f"å¼‚æ­¥åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False

    async def backup_file(
        self, file_path: Union[str, Path], backup_suffix: str = ".backup"
    ) -> Optional[Path]:
        """å¼‚æ­¥å¤‡ä»½æ–‡ä»¶"""
        try:
            path = Path(file_path)
            if not await aiofiles.os.path.exists(path):
                return None

            backup_path = path.with_suffix(path.suffix + backup_suffix)

            # è¯»å–åŸæ–‡ä»¶
            content = await self.read_text(path)
            if content is None:
                return None

            # å†™å…¥å¤‡ä»½
            success = await self.write_text(backup_path, content)
            if success:
                logger.debug(f"ğŸ’¾ ASYNC BACKUP: {path.name} -> {backup_path.name}")
                return backup_path

            return None

        except Exception as e:
            logger.error(f"å¼‚æ­¥å¤‡ä»½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    async def batch_read_json(
        self, file_paths: List[Union[str, Path]], default: Any = None
    ) -> Dict[str, Any]:
        """æ‰¹é‡å¼‚æ­¥è¯»å–JSONæ–‡ä»¶"""

        async def read_single(path):
            return str(path), await self.read_json(path, default)

        results = await asyncio.gather(*[read_single(path) for path in file_paths])
        return dict(results)

    async def batch_write_json(
        self, file_data: Dict[Union[str, Path], Any], **kwargs
    ) -> Dict[str, bool]:
        """æ‰¹é‡å¼‚æ­¥å†™å…¥JSONæ–‡ä»¶"""

        async def write_single(path, data):
            return str(path), await self.write_json(path, data, **kwargs)

        results = await asyncio.gather(
            *[write_single(path, data) for path, data in file_data.items()]
        )
        return dict(results)


# å…¨å±€å¼‚æ­¥æ–‡ä»¶ç®¡ç†å™¨å®ä¾‹
_async_file_manager: Optional[AsyncFileManager] = None


def get_async_file_manager() -> AsyncFileManager:
    """è·å–å…¨å±€å¼‚æ­¥æ–‡ä»¶ç®¡ç†å™¨"""
    global _async_file_manager
    if _async_file_manager is None:
        _async_file_manager = AsyncFileManager()
    return _async_file_manager


# ä¾¿æ·å‡½æ•°
async def async_read_json(file_path: Union[str, Path], default: Any = None) -> Any:
    """ä¾¿æ·çš„å¼‚æ­¥JSONè¯»å–å‡½æ•°"""
    return await get_async_file_manager().read_json(file_path, default)


async def async_write_json(file_path: Union[str, Path], data: Any, **kwargs) -> bool:
    """ä¾¿æ·çš„å¼‚æ­¥JSONå†™å…¥å‡½æ•°"""
    return await get_async_file_manager().write_json(file_path, data, **kwargs)


async def async_read_yaml(file_path: Union[str, Path], default: Any = None) -> Any:
    """ä¾¿æ·çš„å¼‚æ­¥YAMLè¯»å–å‡½æ•°"""
    return await get_async_file_manager().read_yaml(file_path, default)


async def async_write_yaml(file_path: Union[str, Path], data: Any, **kwargs) -> bool:
    """ä¾¿æ·çš„å¼‚æ­¥YAMLå†™å…¥å‡½æ•°"""
    return await get_async_file_manager().write_yaml(file_path, data, **kwargs)


async def async_read_text(
    file_path: Union[str, Path], encoding: str = "utf-8"
) -> Optional[str]:
    """ä¾¿æ·çš„å¼‚æ­¥æ–‡æœ¬è¯»å–å‡½æ•°"""
    return await get_async_file_manager().read_text(file_path, encoding)


async def async_write_text(file_path: Union[str, Path], content: str, **kwargs) -> bool:
    """ä¾¿æ·çš„å¼‚æ­¥æ–‡æœ¬å†™å…¥å‡½æ•°"""
    return await get_async_file_manager().write_text(file_path, content, **kwargs)
