"""
è¯·æ±‚çº§ç¼“å­˜ç³»ç»Ÿ - ä¼˜åŒ–æ¨¡å‹é€‰æ‹©æ€§èƒ½
Created: 2025å¹´1æœˆ
"""

import hashlib
import time
import json
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import asyncio
import logging

from ..config_models import Channel

logger = logging.getLogger(__name__)


@dataclass
class RequestFingerprint:
    """è¯·æ±‚æŒ‡çº¹ï¼Œç”¨äºç¼“å­˜é”®ç”Ÿæˆ"""
    model: str
    routing_strategy: str = "balanced"
    required_capabilities: Optional[List[str]] = None
    min_context_length: Optional[int] = None
    max_cost_per_1k: Optional[float] = None
    prefer_local: bool = False
    exclude_providers: Optional[List[str]] = None
    # æ–°å¢å½±å“è·¯ç”±çš„å‚æ•°
    max_tokens: Optional[int] = None
    temperature: Optional[float] = None
    stream: bool = False
    has_functions: bool = False  # æ˜¯å¦æœ‰function_callingéœ€æ±‚
    
    def to_cache_key(self) -> str:
        """ç”Ÿæˆç¼“å­˜é”®çš„Hashå€¼"""
        # åˆ›å»ºæ ‡å‡†åŒ–çš„æŒ‡çº¹å­—å…¸
        fingerprint_dict = {
            "model": self.model.lower().strip(),
            "routing_strategy": self.routing_strategy,
            "required_capabilities": sorted(self.required_capabilities or []),
            "min_context_length": self.min_context_length,
            "max_cost_per_1k": self.max_cost_per_1k,
            "prefer_local": self.prefer_local,
            "exclude_providers": sorted(self.exclude_providers or []),
            # æ–°å¢å‚æ•°
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "stream": self.stream,
            "has_functions": self.has_functions
        }
        
        # è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ï¼ˆç¡®ä¿keyæ’åºï¼‰
        fingerprint_json = json.dumps(fingerprint_dict, sort_keys=True)
        
        # ç”ŸæˆSHA-256 Hash - ä½¿ç”¨32ä½é¿å…ç¢°æ’é£é™©
        hash_object = hashlib.sha256(fingerprint_json.encode('utf-8'))
        return f"req_{hash_object.hexdigest()[:32]}"  # ä½¿ç”¨32ä½å‡å°‘ç¢°æ’é£é™©


@dataclass 
class CachedModelSelection:
    """ç¼“å­˜çš„æ¨¡å‹é€‰æ‹©ç»“æœ"""
    primary_channel: Channel
    backup_channels: List[Channel]
    selection_reason: str
    cost_estimate: float
    created_at: datetime
    expires_at: datetime
    request_count: int = 0
    last_used_at: Optional[datetime] = None
    
    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²è¿‡æœŸ"""
        return datetime.now() > self.expires_at
    
    def is_valid(self) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆæœªè¿‡æœŸä¸”æ¸ é“å¥åº·ï¼‰"""
        if self.is_expired():
            return False
        
        # æ£€æŸ¥ä¸»è¦æ¸ é“æ˜¯å¦ä»ç„¶å¥åº·
        if not self.primary_channel.enabled:
            return False
            
        return True
    
    def mark_used(self):
        """æ ‡è®°ä¸ºå·²ä½¿ç”¨"""
        self.request_count += 1
        self.last_used_at = datetime.now()


class RequestModelCache:
    """è¯·æ±‚çº§æ¨¡å‹é€‰æ‹©ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, 
                 default_ttl_seconds: int = 60,
                 max_cache_entries: int = 1000,
                 cleanup_interval_seconds: int = 300):
        """
        Args:
            default_ttl_seconds: é»˜è®¤ç¼“å­˜TTLï¼ˆç§’ï¼‰
            max_cache_entries: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
            cleanup_interval_seconds: æ¸…ç†é—´éš”ï¼ˆç§’ï¼‰
        """
        self.default_ttl = default_ttl_seconds
        self.max_entries = max_cache_entries
        self.cleanup_interval = cleanup_interval_seconds
        
        # ç¼“å­˜å­˜å‚¨: {cache_key: CachedModelSelection}
        self._cache: Dict[str, CachedModelSelection] = {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._stats = {
            "hits": 0,
            "misses": 0,
            "invalidations": 0,
            "cleanup_runs": 0
        }
        
        # å¼‚æ­¥é”ä¿æŠ¤å¹¶å‘è®¿é—®
        self._lock = asyncio.Lock()
        
        # æœ€åæ¸…ç†æ—¶é—´ï¼ˆåŒæ­¥æ¸…ç†æœºåˆ¶ï¼‰
        self._last_cleanup = datetime.now()
    
    def _maybe_cleanup(self):
        """æŒ‰éœ€æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆåŒæ­¥æœºåˆ¶ï¼Œé¿å…å¼‚æ­¥ä»»åŠ¡å¤æ‚æ€§ï¼‰"""
        now = datetime.now()
        if (now - self._last_cleanup).total_seconds() > self.cleanup_interval:
            self._cleanup_expired_sync()
            self._last_cleanup = now
    
    async def get_cached_selection(self, fingerprint: RequestFingerprint) -> Optional[CachedModelSelection]:
        """è·å–ç¼“å­˜çš„æ¨¡å‹é€‰æ‹©ç»“æœ"""
        cache_key = fingerprint.to_cache_key()
        
        async with self._lock:
            # æŒ‰éœ€æ¸…ç†
            self._maybe_cleanup()
            
            if cache_key not in self._cache:
                self._stats["misses"] += 1
                logger.debug(f"ğŸš« CACHE MISS: {cache_key} (model: {fingerprint.model})")
                return None
            
            cached_result = self._cache[cache_key]
            
            # æ£€æŸ¥ç¼“å­˜æœ‰æ•ˆæ€§
            if not cached_result.is_valid():
                # ç¼“å­˜å¤±æ•ˆï¼Œåˆ é™¤å¹¶è¿”å›None
                del self._cache[cache_key]
                self._stats["invalidations"] += 1
                logger.info(f"âŒ CACHE INVALIDATED: {cache_key} (expired or unhealthy)")
                return None
            
            # ç¼“å­˜å‘½ä¸­
            cached_result.mark_used()
            self._stats["hits"] += 1
            
            age_seconds = (datetime.now() - cached_result.created_at).total_seconds()
            logger.debug(f"âœ… CACHE HIT: {cache_key} "
                       f"(model: {fingerprint.model}, age: {age_seconds:.1f}s, uses: {cached_result.request_count})")
            
            return cached_result
    
    async def cache_selection(self, 
                             fingerprint: RequestFingerprint,
                             primary_channel: Channel,
                             backup_channels: List[Channel],
                             selection_reason: str,
                             cost_estimate: float,
                             ttl_seconds: Optional[int] = None) -> str:
        """ç¼“å­˜æ¨¡å‹é€‰æ‹©ç»“æœ"""
        
        cache_key = fingerprint.to_cache_key()
        ttl = ttl_seconds or self.default_ttl
        
        async with self._lock:
            # æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
            if len(self._cache) >= self.max_entries:
                self._evict_lru_sync()
            
            now = datetime.now()
            expires_at = now + timedelta(seconds=ttl)
            
            cached_selection = CachedModelSelection(
                primary_channel=primary_channel,
                backup_channels=backup_channels[:5],  # é™åˆ¶å¤‡é€‰æ•°é‡
                selection_reason=selection_reason,
                cost_estimate=cost_estimate,
                created_at=now,
                expires_at=expires_at
            )
            
            self._cache[cache_key] = cached_selection
            
            logger.debug(f"ğŸ’¾ CACHED: {cache_key} -> {primary_channel.name} "
                       f"(ttl: {ttl}s, backups: {len(backup_channels)}, cost: ${cost_estimate:.4f})")
            
            return cache_key
    
    def invalidate_channel(self, channel_id: str):
        """ä½¿ç‰¹å®šæ¸ é“ç›¸å…³çš„ç¼“å­˜å¤±æ•ˆ"""
        invalidated_keys = []
        
        for cache_key, cached_result in list(self._cache.items()):
            if (cached_result.primary_channel.id == channel_id or
                any(backup.id == channel_id for backup in cached_result.backup_channels)):
                del self._cache[cache_key]
                invalidated_keys.append(cache_key)
        
        if invalidated_keys:
            self._stats["invalidations"] += len(invalidated_keys)
            logger.info(f"ğŸ—‘ï¸  INVALIDATED {len(invalidated_keys)} cache entries for channel: {channel_id}")
    
    def invalidate_model(self, model_name: str):
        """ä½¿ç‰¹å®šæ¨¡å‹ç›¸å…³çš„ç¼“å­˜å¤±æ•ˆï¼ˆåŸºäºcache_keyå‰ç¼€åŒ¹é…ï¼‰"""
        # æ³¨æ„ï¼šç”±äºcache_keyæ˜¯Hashï¼Œæ— æ³•ç›´æ¥æŒ‰æ¨¡å‹ååŒ¹é…
        # è¿™é‡Œé‡‡ç”¨ä¿å®ˆç­–ç•¥ï¼šæ¸…ç©ºæ‰€æœ‰ç¼“å­˜
        cleared_count = len(self._cache)
        self._cache.clear()
        self._stats["invalidations"] += cleared_count
        logger.warning(f"ğŸ—‘ï¸  CLEARED ALL CACHE due to model update: {model_name} ({cleared_count} entries)")
    
    def _cleanup_expired_sync(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆå†…éƒ¨åŒæ­¥æ–¹æ³•ï¼‰"""
        expired_keys = []
        now = datetime.now()
        
        for cache_key, cached_result in list(self._cache.items()):
            if cached_result.is_expired():
                expired_keys.append(cache_key)
        
        for key in expired_keys:
            del self._cache[key]
        
        if expired_keys:
            self._stats["cleanup_runs"] += 1
            self._stats["invalidations"] += len(expired_keys)
            logger.debug(f"ğŸ§¹ CLEANUP: Removed {len(expired_keys)} expired cache entries")
    
    def _evict_lru_sync(self):
        """LRUæ·˜æ±°ç­–ç•¥ï¼ˆå†…éƒ¨åŒæ­¥æ–¹æ³•ï¼‰"""
        if not self._cache:
            return
        
        # æ‰¾åˆ°æœ€ä¹…æœªä½¿ç”¨çš„æ¡ç›®ï¼ˆä¼˜åŒ–ä¸ºå•è¡Œï¼‰
        lru_key = min(self._cache.keys(), 
                     key=lambda k: self._cache[k].last_used_at or self._cache[k].created_at)
        
        if lru_key:
            del self._cache[lru_key]
            logger.debug(f"ğŸ—‘ï¸  LRU EVICTED: {lru_key}")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self._stats["hits"] + self._stats["misses"]
        hit_rate = (self._stats["hits"] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            "cache_entries": len(self._cache),
            "max_entries": self.max_entries,
            "hit_rate_percent": round(hit_rate, 2),
            "total_hits": self._stats["hits"],
            "total_misses": self._stats["misses"],
            "total_invalidations": self._stats["invalidations"],
            "cleanup_runs": self._stats["cleanup_runs"],
            "default_ttl_seconds": self.default_ttl
        }
    
    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        cleared_count = len(self._cache)
        self._cache.clear()
        logger.info(f"ğŸ—‘ï¸  CLEARED ALL CACHE: {cleared_count} entries removed")
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if self._cleanup_task and not self._cleanup_task.done():
            self._cleanup_task.cancel()


# å…¨å±€ç¼“å­˜å®ä¾‹
_global_cache: Optional[RequestModelCache] = None


def get_request_cache() -> RequestModelCache:
    """è·å–å…¨å±€è¯·æ±‚ç¼“å­˜å®ä¾‹"""
    global _global_cache
    if _global_cache is None:
        _global_cache = RequestModelCache(
            default_ttl_seconds=60,      # 1åˆ†é’Ÿé»˜è®¤TTL
            max_cache_entries=1000,      # æœ€å¤§1000ä¸ªç¼“å­˜æ¡ç›®  
            cleanup_interval_seconds=300 # 5åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
        )
    return _global_cache