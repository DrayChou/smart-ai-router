"""
å†…å­˜ç´¢å¼•ç³»ç»Ÿ - æ¶ˆé™¤æ–‡ä»¶I/Oæ€§èƒ½ç“¶é¢ˆ
æ„å»ºé«˜æ€§èƒ½çš„æ ‡ç­¾â†’æ¨¡å‹æ˜ å°„ç´¢å¼•
"""

import logging
import threading
import time
from collections import defaultdict
from dataclasses import dataclass
from typing import Any, Optional

logger = logging.getLogger(__name__)


@dataclass
class ModelInfo:
    """æ¨¡å‹ä¿¡æ¯"""

    channel_id: str
    model_name: str
    provider: str
    tags: set[str]
    pricing: Optional[dict] = None
    capabilities: Optional[dict] = None
    specs: Optional[dict] = None  # æ¨¡å‹è§„æ ¼ä¿¡æ¯ï¼ˆå‚æ•°é‡ã€ä¸Šä¸‹æ–‡é•¿åº¦ç­‰ï¼‰
    # å¥åº·çŠ¶æ€ç¼“å­˜
    health_score: Optional[float] = None
    health_cached_at: Optional[float] = None  # Unixæ—¶é—´æˆ³


@dataclass
class IndexStats:
    """ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""

    total_models: int
    total_channels: int
    total_tags: int
    build_time_ms: float
    memory_usage_mb: float


class MemoryModelIndex:
    """å†…å­˜æ¨¡å‹ç´¢å¼• - é«˜æ€§èƒ½æ ‡ç­¾æŸ¥è¯¢"""

    def __init__(self):
        self._lock = threading.RLock()

        # æ ¸å¿ƒç´¢å¼•ç»“æ„
        self._tag_to_models: dict[str, set[tuple[str, str]]] = defaultdict(
            set
        )  # tag -> {(channel_id, model_name)}
        self._channel_to_models: dict[str, set[str]] = defaultdict(
            set
        )  # channel_id -> {model_names}
        self._model_info: dict[tuple[str, str], ModelInfo] = (
            {}
        )  # (channel_id, model_name) -> ModelInfo

        # æ€§èƒ½ç»Ÿè®¡
        self._stats = IndexStats(0, 0, 0, 0.0, 0.0)

        # æ™ºèƒ½é‡å»ºæ§åˆ¶
        self._last_build_time = 0.0
        self._last_build_hash = None
        self._min_rebuild_interval = 30  # æœ€å°é‡å»ºé—´éš”30ç§’
        self._build_count = 0
        self._incremental_updates_count = 0

        logger.info(
            "ğŸš€ MemoryModelIndex initialized - ready for high-performance tag queries"
        )

    def build_index_from_cache(
        self, model_cache: dict[str, dict], channel_configs: Optional[list[dict]] = None
    ) -> IndexStats:
        """
        ä»æ¨¡å‹ç¼“å­˜æ„å»ºå†…å­˜ç´¢å¼•ï¼Œæ”¯æŒæ™ºèƒ½é‡å»ºæ§åˆ¶

        Args:
            model_cache: åŸå§‹æ¨¡å‹ç¼“å­˜æ•°æ®
            channel_configs: æ¸ é“é…ç½®ä¿¡æ¯åˆ—è¡¨

        Returns:
            ç´¢å¼•æ„å»ºç»Ÿè®¡ä¿¡æ¯
        """
        current_time = time.time()

        # è®¡ç®—ç¼“å­˜æ•°æ®çš„å“ˆå¸Œå€¼æ¥æ£€æµ‹å˜åŒ–
        import hashlib

        cache_str = str(sorted(model_cache.items()))
        cache_hash = hashlib.sha256(cache_str.encode()).hexdigest()

        # æ™ºèƒ½é‡å»ºåˆ¤æ–­
        if self._should_skip_rebuild(current_time, cache_hash):
            logger.info(
                f"âš¡ INDEX SKIP: Using existing index ({self._stats.total_models} models, {self._stats.total_tags} tags)"
            )
            return self._stats

        start_time = time.time()

        with self._lock:
            # æ¸…ç©ºç°æœ‰ç´¢å¼•
            self._tag_to_models.clear()
            self._channel_to_models.clear()
            self._model_info.clear()

            # æ„å»ºæ¸ é“æ ‡ç­¾æ˜ å°„
            self._channel_tag_map = {}
            if channel_configs:
                logger.info(
                    f"ğŸ·ï¸ CHANNEL TAG MAPPING: Processing {len(channel_configs)} channel configs"
                )
                for channel_config in channel_configs:
                    # å¤„ç†ä¸åŒæ ¼å¼çš„æ¸ é“é…ç½®
                    if hasattr(channel_config, "id"):  # Pydanticå¯¹è±¡
                        channel_id = channel_config.id
                        tags = getattr(channel_config, "tags", [])
                        logger.debug(f"PYDANTIC CHANNEL: {channel_id} -> {tags}")
                    elif isinstance(channel_config, dict):  # å­—å…¸æ ¼å¼
                        channel_id = channel_config.get("id")
                        tags = channel_config.get("tags", [])
                        logger.debug(f"DICT CHANNEL: {channel_id} -> {tags}")
                    else:
                        logger.debug(f"UNKNOWN CHANNEL TYPE: {type(channel_config)}")
                        continue

                    if channel_id and tags:
                        self._channel_tag_map[channel_id] = set(tags)
                        logger.info(f"âœ… CHANNEL TAGS MAPPED: {channel_id} -> {tags}")
                    elif channel_id:
                        # ğŸš€ è‡ªåŠ¨æ¨æ–­æ¸ é“æ ‡ç­¾ï¼ˆåŸºäºæ¸ é“åç§°ï¼‰
                        inferred_tags = self._infer_channel_tags(channel_id)
                        if inferred_tags:
                            self._channel_tag_map[channel_id] = inferred_tags
                            logger.info(
                                f"ğŸ·ï¸ INFERRED CHANNEL TAGS: {channel_id} -> {inferred_tags}"
                            )
                        else:
                            logger.warning(
                                f"âš ï¸ CHANNEL NO TAGS: {channel_id} has no tags"
                            )

                logger.info(
                    f"ğŸ·ï¸ CHANNEL TAG MAP BUILT: {len(self._channel_tag_map)} channels with tags"
                )
            else:
                logger.warning("âš ï¸ NO CHANNEL CONFIGS PROVIDED for tag mapping")

            logger.info(
                f"ğŸ”¨ INDEX BUILD: Processing {len(model_cache)} cache entries..."
            )

            total_models = 0
            processed_channels = set()

            # ğŸš€ å¤šProviderå…è´¹ç­–ç•¥ï¼šæ”¶é›†æ‰€æœ‰æ¨¡å‹çš„å®šä»·ä¿¡æ¯
            global_model_pricing = (
                {}
            )  # {model_name: [{'provider': provider, 'is_free': bool, 'channel_id': str}]}

            for cache_key, cache_data in model_cache.items():
                if not isinstance(cache_data, dict):
                    continue

                # æå–æ¸ é“IDï¼ˆå¤„ç†API Keyçº§åˆ«çš„ç¼“å­˜é”®ï¼‰
                channel_id = self._extract_channel_id(cache_key)
                if not channel_id:
                    continue

                processed_channels.add(channel_id)

                # å¤„ç†æ¨¡å‹åˆ—è¡¨
                models = cache_data.get("models", [])
                models_data = cache_data.get("models_data", {})  # æ¨¡å‹è¯¦ç»†è§„æ ¼æ•°æ®
                models_pricing = cache_data.get(
                    "models_pricing", {}
                )  # ğŸš€ æ–°å¢ï¼šæ¨¡å‹å®šä»·æ•°æ®
                provider = cache_data.get("provider", "unknown")

                # ğŸš€ æ”¶é›†å®šä»·ä¿¡æ¯ç”¨äºå¤šProviderå…è´¹ç­–ç•¥
                for model_name in models:
                    if model_name not in global_model_pricing:
                        global_model_pricing[model_name] = []

                    # æ·»åŠ æ­¤Provider/Channelçš„å®šä»·ä¿¡æ¯
                    pricing_info = models_pricing.get(model_name, {})
                    is_free = pricing_info.get("is_free", False)

                    global_model_pricing[model_name].append(
                        {
                            "provider": provider,
                            "channel_id": channel_id,
                            "is_free": is_free,
                            "pricing": pricing_info,
                        }
                    )

                for model_name in models:
                    if not isinstance(model_name, str):
                        continue

                    # ç”ŸæˆåŸºç¡€æ ‡ç­¾
                    tags = self._generate_model_tags(model_name, provider)

                    # ğŸš€ å¤šProviderå…è´¹ç­–ç•¥ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•Provideræä¾›å…è´¹
                    if model_name in global_model_pricing:
                        provider_infos = global_model_pricing[model_name]
                        has_free_provider = any(
                            info.get("is_free", False) for info in provider_infos
                        )

                        if has_free_provider:
                            tags.add("free")
                            logger.debug(
                                f"ğŸ†“ æ¨¡å‹ {model_name} æ ‡è®°ä¸ºå…è´¹ (è·¨Provideræ£€æµ‹)"
                            )

                    # ğŸš€ åŠ¨æ€ä»·æ ¼æ£€æµ‹ï¼šæ£€æŸ¥å½“å‰æ¸ é“çš„å®šä»·ä¿¡æ¯
                    if model_name in models_pricing:
                        pricing_info = models_pricing[model_name]
                        is_free_by_pricing = pricing_info.get("is_free", False)
                        prompt_price = pricing_info.get("prompt", 0)
                        completion_price = pricing_info.get("completion", 0)

                        # å¦‚æœå½“å‰æ¸ é“ä»·æ ¼ä¸º0ï¼Œæ·»åŠ ä¸´æ—¶freeæ ‡ç­¾
                        if is_free_by_pricing or (
                            prompt_price == 0 and completion_price == 0
                        ):
                            tags.add("free")
                            logger.debug(
                                f"ğŸ†“ æ¨¡å‹ {model_name} æ ‡è®°ä¸ºå…è´¹ (å½“å‰æ¸ é“ {channel_id} å®šä»·ä¸º0)"
                            )

                    # ğŸš€ æ¸ é“çº§åˆ«ä»·æ ¼æ£€æµ‹ï¼šæ£€æŸ¥æ¸ é“é…ç½®çš„cost_per_token
                    try:
                        channel_cost = cache_data.get("cost_per_token", {})
                        if isinstance(channel_cost, dict):
                            input_cost = channel_cost.get("input", 0)
                            output_cost = channel_cost.get("output", 0)
                            if input_cost == 0 and output_cost == 0:
                                tags.add("free")
                                logger.debug(
                                    f"ğŸ†“ æ¨¡å‹ {model_name} æ ‡è®°ä¸ºå…è´¹ (æ¸ é“ {channel_id} é…ç½®cost_per_tokenä¸º0)"
                                )
                    except Exception as e:
                        logger.debug(f"æ¸ é“ä»·æ ¼æ£€æµ‹å¤±è´¥ {channel_id}: {e}")

                    # ğŸš€ åˆå¹¶æ¸ é“çº§åˆ«çš„æ ‡ç­¾
                    channel_tags = self._get_channel_tags(channel_id)
                    if channel_tags:
                        tags = tags.union(channel_tags)

                    # ğŸ·ï¸ æ·»åŠ æ¸ é“å•†æ ‡ç­¾ (æå–æ¸ é“IDçš„ç¬¬ä¸€éƒ¨åˆ†ä½œä¸ºæ¸ é“å•†æ ‡ç­¾)
                    provider_tag = self._extract_provider_tag(channel_id)
                    if provider_tag:
                        tags.add(provider_tag)

                    # è·å–æ¨¡å‹è¯¦ç»†è§„æ ¼
                    model_specs = models_data.get(model_name, {}) if models_data else {}

                    # ğŸš€ ç¡®ä¿åŒ…å«å…³é”®è§„æ ¼ä¿¡æ¯
                    if not model_specs:
                        # å°è¯•ä»å…¶ä»–ä½ç½®è·å–è§„æ ¼ä¿¡æ¯
                        model_specs = self._ensure_model_specs(model_name, cache_data)

                    # åˆ›å»ºæ¨¡å‹ä¿¡æ¯
                    model_key = (channel_id, model_name)
                    model_info = ModelInfo(
                        channel_id=channel_id,
                        model_name=model_name,
                        provider=provider,
                        tags=tags,
                        pricing=cache_data.get("models_pricing", {}).get(model_name),
                        capabilities=self._extract_capabilities(cache_data, model_name),
                    )

                    # æ·»åŠ æ¨¡å‹è§„æ ¼åˆ°ModelInfoï¼ˆæ‰©å±•ç”¨äºå¥åº·æ£€æŸ¥ä¼˜åŒ–ï¼‰
                    if model_specs:
                        model_info.specs = model_specs
                    else:
                        # å³ä½¿æ²¡æœ‰è¯¦ç»†è§„æ ¼ï¼Œä¹Ÿç¡®ä¿åŒ…å«åŸºæœ¬åˆ†æç»“æœ
                        model_info.specs = self._get_basic_model_specs(model_name)

                    # æ›´æ–°ç´¢å¼•
                    self._model_info[model_key] = model_info
                    self._channel_to_models[channel_id].add(model_name)

                    # æ›´æ–°æ ‡ç­¾ç´¢å¼•
                    for tag in tags:
                        self._tag_to_models[tag].add(model_key)

                    total_models += 1

            # æ„å»ºç»Ÿè®¡ä¿¡æ¯
            build_time_ms = (time.time() - start_time) * 1000
            self._stats = IndexStats(
                total_models=total_models,
                total_channels=len(processed_channels),
                total_tags=len(self._tag_to_models),
                build_time_ms=build_time_ms,
                memory_usage_mb=self._estimate_memory_usage(),
            )

            self._last_build_time = current_time
            self._last_build_hash = cache_hash
            self._build_count += 1

            # ğŸš€ ç»Ÿè®¡å¤šProviderå…è´¹ç­–ç•¥çš„æ•ˆæœ
            free_models_count = len(self._tag_to_models.get("free", set()))
            multi_provider_free = 0

            for _model_name, provider_infos in global_model_pricing.items():
                if len(provider_infos) > 1:  # å¤šProvider
                    has_free = any(
                        info.get("is_free", False) for info in provider_infos
                    )
                    if has_free:
                        multi_provider_free += 1

            logger.info(
                f"âœ… INDEX BUILT: {total_models} models, {len(processed_channels)} channels, "
                f"{len(self._tag_to_models)} tags in {build_time_ms:.1f}ms"
            )
            logger.info(
                f"ğŸ†“ FREE MODELS: {free_models_count} models tagged as free, {multi_provider_free} from multi-provider analysis"
            )

            return self._stats

    def find_models_by_tags(
        self, include_tags: list[str], exclude_tags: list[str] = None
    ) -> list[tuple[str, str]]:
        """
        æ ¹æ®æ ‡ç­¾æŸ¥æ‰¾æ¨¡å‹ï¼ˆè¶…é«˜é€Ÿï¼‰

        Args:
            include_tags: å¿…é¡»åŒ…å«çš„æ ‡ç­¾
            exclude_tags: å¿…é¡»æ’é™¤çš„æ ‡ç­¾

        Returns:
            åŒ¹é…çš„æ¨¡å‹åˆ—è¡¨ [(channel_id, model_name), ...]
        """
        if not include_tags:
            return []

        with self._lock:
            # å¼€å§‹ä»æœ€å°çš„æ ‡ç­¾é›†åˆè¿›è¡Œäº¤é›†è¿ç®—
            tag_sets = [self._tag_to_models.get(tag, set()) for tag in include_tags]
            if not all(tag_sets):
                return []  # å¦‚æœä»»ä½•æ ‡ç­¾éƒ½æ²¡æœ‰åŒ¹é…ï¼Œç›´æ¥è¿”å›ç©º

            # æ‰¾åˆ°æœ€å°çš„é›†åˆä½œä¸ºèµ·ç‚¹ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
            result_set = min(tag_sets, key=len)

            # è®¡ç®—äº¤é›†
            for tag_set in tag_sets:
                if tag_set is not result_set:  # é¿å…è‡ªå·±å’Œè‡ªå·±æ±‚äº¤é›†
                    result_set = result_set.intersection(tag_set)
                    if not result_set:  # å¦‚æœäº¤é›†ä¸ºç©ºï¼Œæå‰é€€å‡º
                        break

            # æ’é™¤ä¸éœ€è¦çš„æ ‡ç­¾
            if exclude_tags and result_set:
                exclude_set = set()
                for tag in exclude_tags:
                    exclude_set.update(self._tag_to_models.get(tag, set()))
                result_set = result_set - exclude_set

            return list(result_set)

    def get_model_info(self, channel_id: str, model_name: str) -> Optional[ModelInfo]:
        """è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
        with self._lock:
            return self._model_info.get((channel_id, model_name))

    def get_model_specs(self, channel_id: str, model_name: str) -> Optional[dict]:
        """è·å–æ¨¡å‹è§„æ ¼ï¼ˆä¼˜åŒ–ç‰ˆï¼Œæ›¿ä»£æ–‡ä»¶I/Oï¼‰"""
        with self._lock:
            model_info = self._model_info.get((channel_id, model_name))
            return model_info.specs if model_info else None

    def get_channel_models(self, channel_id: str) -> set[str]:
        """è·å–æ¸ é“ä¸‹çš„æ‰€æœ‰æ¨¡å‹"""
        with self._lock:
            return self._channel_to_models.get(channel_id, set()).copy()

    def get_health_score(
        self, channel_id: str, cache_ttl: float = 60.0
    ) -> Optional[float]:
        """è·å–å¥åº·è¯„åˆ†ï¼ˆå¸¦ç¼“å­˜TTLæ£€æŸ¥ï¼‰"""
        current_time = time.time()

        with self._lock:
            # æŸ¥æ‰¾è¯¥æ¸ é“ä¸‹çš„ä»»æ„æ¨¡å‹æ¥è·å–å¥åº·çŠ¶æ€
            models = self._channel_to_models.get(channel_id, set())
            if not models:
                return None

            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹çš„å¥åº·çŠ¶æ€ï¼ˆæ¸ é“çº§åˆ«ï¼‰
            first_model = next(iter(models))
            model_info = self._model_info.get((channel_id, first_model))

            if (
                model_info
                and model_info.health_score is not None
                and model_info.health_cached_at is not None
                and (current_time - model_info.health_cached_at) < cache_ttl
            ):
                return model_info.health_score

            return None

    def set_health_score(self, channel_id: str, health_score: float):
        """è®¾ç½®å¥åº·è¯„åˆ†ï¼ˆæ›´æ–°æ‰€æœ‰è¯¥æ¸ é“ä¸‹çš„æ¨¡å‹ï¼‰"""
        current_time = time.time()

        with self._lock:
            models = self._channel_to_models.get(channel_id, set())
            for model_name in models:
                model_info = self._model_info.get((channel_id, model_name))
                if model_info:
                    model_info.health_score = health_score
                    model_info.health_cached_at = current_time

    def get_tag_stats(self) -> dict[str, int]:
        """è·å–æ ‡ç­¾ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            return {tag: len(models) for tag, models in self._tag_to_models.items()}

    def get_stats(self) -> IndexStats:
        """è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            return self._stats

    def is_stale(self, cache_update_time: float) -> bool:
        """æ£€æŸ¥ç´¢å¼•æ˜¯å¦è¿‡æœŸ"""
        return cache_update_time > self._last_build_time

    def needs_rebuild(self, model_cache: dict[str, dict]) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å»ºç´¢å¼•"""
        # ğŸš€ ä¿®å¤ï¼šåªæœ‰åœ¨ç´¢å¼•ä¸ºç©ºæ—¶æ‰å¼ºåˆ¶é‡å»º
        if self._stats.total_models == 0:
            logger.debug("INDEX REBUILD: Index is empty, needs rebuild")
            return True

        # ğŸš€ ä¿®å¤ï¼šæ›´æ™ºèƒ½çš„ç¼“å­˜å¤§å°æ£€æŸ¥
        current_cache_size = len(model_cache)
        cached_channels = self._stats.total_channels

        # ğŸš€ å®¹å¿ç¼“å­˜è¿ç§»é€ æˆçš„å¤§å°å˜åŒ–ï¼ˆä»legacyæ ¼å¼åˆ°API Keyæ ¼å¼ï¼‰
        if current_cache_size < cached_channels:
            # å¦‚æœç¼“å­˜å‡å°‘è¶…è¿‡30%ï¼Œå¯èƒ½æ˜¯è¿ç§»å¯¼è‡´çš„æ¸…ç†ï¼Œéœ€è¦é‡å»º
            reduction_ratio = current_cache_size / cached_channels
            if reduction_ratio < 0.7:  # å‡å°‘è¶…è¿‡30%
                logger.debug(
                    f"INDEX REBUILD: Cache size reduced significantly ({current_cache_size} vs {cached_channels})"
                )
                return True
        elif current_cache_size > cached_channels:
            # ğŸš€ ç¼“å­˜å¢åŠ äº†ï¼Œä»…å½“å¢åŠ è¶…è¿‡50%æ—¶æ‰é‡å»ºï¼ˆæ›´å®½æ¾ï¼‰
            growth_ratio = current_cache_size / cached_channels
            if growth_ratio > 1.5:  # å¢é•¿è¶…è¿‡50%æ‰é‡å»º
                logger.debug(
                    f"INDEX REBUILD: Cache size increased significantly ({current_cache_size} vs {cached_channels})"
                )
                return True

        # ğŸš€ æ›´ç¨³å®šçš„å“ˆå¸Œæ£€æŸ¥ï¼šåŸºäºæ¨¡å‹æ€»æ•°è€Œéç¼“å­˜é”®ç»“æ„
        try:
            total_models_in_cache = sum(
                len(cache_data.get("models", []))
                for cache_data in model_cache.values()
                if isinstance(cache_data, dict)
            )
            if (
                abs(total_models_in_cache - self._stats.total_models)
                > self._stats.total_models * 0.1
            ):  # æ¨¡å‹æ•°é‡å˜åŒ–è¶…è¿‡10%
                logger.debug(
                    f"INDEX REBUILD: Model count changed significantly ({total_models_in_cache} vs {self._stats.total_models})"
                )
                return True
        except Exception as e:
            logger.debug(f"INDEX REBUILD: Error checking model count: {e}")
            pass

        logger.debug(
            f"INDEX REBUILD: No rebuild needed (cache: {current_cache_size}, indexed: {cached_channels})"
        )
        return False  # é»˜è®¤ä¸é‡å»º

    def _extract_channel_id(self, cache_key: str) -> Optional[str]:
        """ä»ç¼“å­˜é”®æå–æ¸ é“ID"""
        if not cache_key:
            return None

        # å¤„ç†API Keyçº§åˆ«çš„ç¼“å­˜é”®æ ¼å¼: "channel_id_apikeyash"
        if "_" in cache_key:
            parts = cache_key.split("_")
            if len(parts) >= 2:
                # æ£€æŸ¥æœ€åä¸€éƒ¨åˆ†æ˜¯å¦ä¸ºhashæ ¼å¼ï¼ˆ8ä½åå…­è¿›åˆ¶ï¼‰
                potential_hash = parts[-1]
                if len(potential_hash) == 8 and all(
                    c in "0123456789abcdef" for c in potential_hash.lower()
                ):
                    return "_".join(parts[:-1])

        # ç›´æ¥è¿”å›ä½œä¸ºæ¸ é“ID
        return cache_key

    def _generate_model_tags(self, model_name: str, provider: str) -> set[str]:
        """ä¸ºæ¨¡å‹ç”Ÿæˆæ ‡ç­¾é›†åˆ"""
        tags = set()

        if not model_name:
            return tags

        model_lower = model_name.lower()

        # æ·»åŠ æä¾›å•†æ ‡ç­¾
        if provider:
            tags.add(provider.lower())

        # ä½¿ç”¨å¤šç§åˆ†éš”ç¬¦åˆ†å‰²æ¨¡å‹åç§°ç”Ÿæˆæ ‡ç­¾
        separators = [":", "/", "@", "-", "_", ",", ".", " "]
        tokens = [model_lower]

        for sep in separators:
            new_tokens = []
            for token in tokens:
                new_tokens.extend(token.split(sep))
            tokens = [t.strip() for t in new_tokens if t.strip()]

        # æ·»åŠ æ‰€æœ‰æœ‰æ•ˆçš„tokenä½œä¸ºæ ‡ç­¾
        for token in tokens:
            if len(token) >= 2:  # è¿‡æ»¤å¤ªçŸ­çš„æ ‡ç­¾
                tags.add(token)

        # ç‰¹æ®Šæ ‡ç­¾è¯†åˆ«
        if any(
            free_indicator in model_lower
            for free_indicator in ["free", "gratis", "å…è´¹"]
        ):
            tags.add("free")

        if any(
            vision_indicator in model_lower
            for vision_indicator in ["vision", "visual", "image", "multimodal"]
        ):
            tags.add("vision")

        if any(
            code_indicator in model_lower
            for code_indicator in ["code", "coder", "coding", "program"]
        ):
            tags.add("code")

        return tags

    def _extract_provider_tag(self, channel_id: str) -> Optional[str]:
        """ä»æ¸ é“IDä¸­æå–æ¸ é“å•†æ ‡ç­¾"""
        if not channel_id:
            return None

        # æå–æ¸ é“IDçš„ç¬¬ä¸€éƒ¨åˆ†ä½œä¸ºæ¸ é“å•†æ ‡ç­¾
        # ä¾‹å¦‚: groq -> groq, openrouter_1 -> openrouter, burn.hair -> burn
        provider_name = channel_id.split(".")[0].lower()

        # è¿‡æ»¤æ‰ä¸€äº›æ— æ„ä¹‰çš„æ ‡ç­¾
        if provider_name and len(provider_name) > 2:
            return provider_name

        return None

    def _get_channel_tags(self, channel_id: str) -> Optional[set[str]]:
        """è·å–æ¸ é“çº§åˆ«çš„æ ‡ç­¾"""
        try:
            # ä¼˜å…ˆä½¿ç”¨åŠ¨æ€æ„å»ºçš„æ¸ é“æ ‡ç­¾æ˜ å°„
            if hasattr(self, "_channel_tag_map") and self._channel_tag_map:
                tags = self._channel_tag_map.get(channel_id)
                if tags:
                    return tags

            # å›é€€åˆ°ç¡¬ç¼–ç æ˜ å°„ï¼ˆå…¼å®¹æ€§ï¼‰
            fallback_map = {
                "ollama_local": {"free", "local", "ollama"},
                "lmstudio_local": {"free", "local", "lmstudio"},
            }
            return fallback_map.get(channel_id)
        except Exception as e:
            logger.debug(f"Failed to get channel tags for {channel_id}: {e}")
        return None

    def _extract_capabilities(
        self, cache_data: dict, model_name: str
    ) -> Optional[dict]:
        """æå–æ¨¡å‹èƒ½åŠ›ä¿¡æ¯"""
        capabilities_data = cache_data.get("models_capabilities", {})
        return capabilities_data.get(model_name) if capabilities_data else None

    def _ensure_model_specs(self, model_name: str, cache_data: dict) -> dict:
        """ç¡®ä¿æ¨¡å‹è§„æ ¼ä¿¡æ¯å­˜åœ¨"""
        specs = {}

        # å°è¯•ä»ä¸åŒä½ç½®è·å–è§„æ ¼ä¿¡æ¯
        if "models" in cache_data and isinstance(cache_data["models"], dict):
            specs = cache_data["models"].get(model_name, {})

        # å¦‚æœä»ç„¶æ²¡æœ‰è§„æ ¼ä¿¡æ¯ï¼Œä½¿ç”¨æ¨¡å‹åˆ†æå™¨
        if not specs.get("parameter_count") or not specs.get("context_length"):
            try:
                from core.utils.model_analyzer import get_model_analyzer

                analyzer = get_model_analyzer()
                analyzed_specs = analyzer.analyze_model(model_name)

                # ç¡®ä¿åŒ…å«å…³é”®è§„æ ¼ä¿¡æ¯
                if analyzed_specs.parameter_count:
                    specs["parameter_count"] = analyzed_specs.parameter_count
                if analyzed_specs.context_length:
                    specs["context_length"] = analyzed_specs.context_length

            except Exception:
                pass

        return specs

    def _get_basic_model_specs(self, model_name: str) -> dict:
        """è·å–åŸºæœ¬æ¨¡å‹è§„æ ¼ä¿¡æ¯ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        try:
            from core.utils.model_analyzer import get_model_analyzer

            analyzer = get_model_analyzer()
            analyzed_specs = analyzer.analyze_model(model_name)

            return {
                "parameter_count": analyzed_specs.parameter_count,
                "context_length": analyzed_specs.context_length,
            }
        except Exception:
            # æä¾›é»˜è®¤å€¼
            return {"parameter_count": 0, "context_length": 2048}  # é»˜è®¤ä¸Šä¸‹æ–‡é•¿åº¦

    def _infer_channel_tags(self, channel_id: str) -> set:
        """åŸºäºæ¸ é“IDè‡ªåŠ¨æ¨æ–­æ ‡ç­¾"""
        inferred_tags = set()
        channel_lower = channel_id.lower()

        # åŸºäºæ¸ é“åç§°çš„å¸¸è§æ ‡ç­¾æ¨æ–­
        tag_mappings = [
            ("openrouter", {"openrouter", "aggregator", "multi-provider"}),
            ("groq", {"groq", "fast", "inference-engine"}),
            ("ollama", {"ollama", "local", "self-hosted", "free"}),
            ("lmstudio", {"lmstudio", "local", "self-hosted", "free"}),
            ("openai", {"openai", "official", "premium"}),
            ("anthropic", {"anthropic", "official", "premium"}),
            ("free", {"free", "gratis"}),
            ("pro", {"pro", "premium", "paid"}),
            ("turbo", {"turbo", "fast"}),
            ("mini", {"mini", "small", "efficient"}),
            ("max", {"max", "large", "powerful"}),
            ("vision", {"vision", "multimodal", "image"}),
            ("code", {"code", "programming", "developer"}),
        ]

        for keyword, tags in tag_mappings:
            if keyword in channel_lower:
                inferred_tags.update(tags)

        # æ·»åŠ æä¾›å•†æ ‡ç­¾
        provider_tag = self._extract_provider_tag(channel_id)
        if provider_tag:
            inferred_tags.add(provider_tag)

        return inferred_tags

    def _estimate_memory_usage(self) -> float:
        """ä¼°ç®—å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        import sys

        total_size = 0
        total_size += sys.getsizeof(self._tag_to_models)
        total_size += sys.getsizeof(self._channel_to_models)
        total_size += sys.getsizeof(self._model_info)

        # ä¼°ç®—å†…éƒ¨æ•°æ®ç»“æ„çš„å¤§å°
        for tag_set in self._tag_to_models.values():
            total_size += sys.getsizeof(tag_set)

        for model_set in self._channel_to_models.values():
            total_size += sys.getsizeof(model_set)

        return total_size / 1024 / 1024

    def _should_skip_rebuild(self, current_time: float, cache_hash: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡é‡å»º"""
        # å¦‚æœä»æœªæ„å»ºè¿‡ï¼Œå¿…é¡»æ„å»º
        if self._build_count == 0:
            return False

        # æ—¶é—´é—´éš”æ£€æŸ¥ï¼šå¦‚æœè·ç¦»ä¸Šæ¬¡æ„å»ºæ—¶é—´å¤ªçŸ­ï¼Œè·³è¿‡
        time_since_last_build = current_time - self._last_build_time
        if time_since_last_build < self._min_rebuild_interval:
            logger.debug(
                f"INDEX SKIP: Too soon to rebuild ({time_since_last_build:.1f}s < {self._min_rebuild_interval}s)"
            )
            return True

        # å†…å®¹å˜åŒ–æ£€æŸ¥ï¼šå¦‚æœç¼“å­˜å†…å®¹æ²¡æœ‰å˜åŒ–ï¼Œè·³è¿‡
        if self._last_build_hash == cache_hash:
            logger.debug(
                f"INDEX SKIP: Cache content unchanged (hash: {cache_hash[:8]}...)"
            )
            return True

        return False

    def add_incremental_model(
        self, channel_id: str, model_name: str, provider: str = "unknown"
    ):
        """å¢é‡æ·»åŠ å•ä¸ªæ¨¡å‹ï¼ˆé¿å…å…¨é‡é‡å»ºï¼‰"""
        with self._lock:
            tags = self._generate_model_tags(model_name, provider)
            model_key = (channel_id, model_name)

            # åˆ›å»ºæ¨¡å‹ä¿¡æ¯
            model_info = ModelInfo(
                channel_id=channel_id,
                model_name=model_name,
                provider=provider,
                tags=tags,
            )

            # æ›´æ–°ç´¢å¼•
            self._model_info[model_key] = model_info
            self._channel_to_models[channel_id].add(model_name)

            # æ›´æ–°æ ‡ç­¾ç´¢å¼•
            for tag in tags:
                self._tag_to_models[tag].add(model_key)

            self._incremental_updates_count += 1
            logger.debug(
                f"ğŸ“ˆ INDEX INCREMENT: Added {model_name} to channel {channel_id}"
            )

    def remove_channel_models(self, channel_id: str):
        """ç§»é™¤æŸä¸ªæ¸ é“çš„æ‰€æœ‰æ¨¡å‹"""
        with self._lock:
            models_to_remove = list(self._channel_to_models.get(channel_id, set()))

            for model_name in models_to_remove:
                model_key = (channel_id, model_name)

                # ä»æ¨¡å‹ä¿¡æ¯ä¸­ç§»é™¤
                if model_key in self._model_info:
                    model_info = self._model_info[model_key]
                    del self._model_info[model_key]

                    # ä»æ ‡ç­¾ç´¢å¼•ä¸­ç§»é™¤
                    for tag in model_info.tags:
                        self._tag_to_models[tag].discard(model_key)
                        # å¦‚æœæ ‡ç­¾æ²¡æœ‰ä»»ä½•æ¨¡å‹äº†ï¼Œåˆ é™¤æ ‡ç­¾
                        if not self._tag_to_models[tag]:
                            del self._tag_to_models[tag]

            # æ¸…ç©ºæ¸ é“æ¨¡å‹åˆ—è¡¨
            if channel_id in self._channel_to_models:
                del self._channel_to_models[channel_id]

            logger.debug(
                f"ğŸ—‘ï¸ INDEX REMOVE: Removed {len(models_to_remove)} models from channel {channel_id}"
            )

    def get_build_stats(self) -> dict[str, Any]:
        """è·å–æ„å»ºç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_builds": self._build_count,
            "last_build_time": self._last_build_time,
            "incremental_updates": self._incremental_updates_count,
            "min_rebuild_interval": self._min_rebuild_interval,
            "models_count": len(self._model_info),
            "channels_count": len(self._channel_to_models),
            "tags_count": len(self._tag_to_models),
        }


# å…¨å±€ç´¢å¼•å®ä¾‹
_memory_index: Optional[MemoryModelIndex] = None


def get_memory_index() -> MemoryModelIndex:
    """è·å–å…¨å±€å†…å­˜ç´¢å¼•å®ä¾‹"""
    global _memory_index
    if _memory_index is None:
        _memory_index = MemoryModelIndex()
    return _memory_index


def reset_memory_index():
    """é‡ç½®å…¨å±€å†…å­˜ç´¢å¼•å®ä¾‹ï¼ˆç”¨äºä¿®å¤åçš„é‡æ–°æ„å»ºï¼‰"""
    global _memory_index
    _memory_index = None


def rebuild_index_if_needed(
    model_cache: dict[str, dict],
    force_rebuild: bool = False,
    channel_configs: Optional[list[dict]] = None,
) -> IndexStats:
    """æŒ‰éœ€é‡å»ºç´¢å¼•"""
    index = get_memory_index()

    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å»ºï¼ˆè¿™é‡Œå¯ä»¥åŸºäºç¼“å­˜æ›´æ–°æ—¶é—´ç­‰æ¡ä»¶ï¼‰
    if force_rebuild:
        return index.build_index_from_cache(model_cache, channel_configs)

    return index.get_stats()
