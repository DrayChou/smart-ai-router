#!/usr/bin/env python3
"""
ä»»åŠ¡ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰åå°ä»»åŠ¡
"""

import asyncio
from typing import Dict, Any, Optional
import logging

from .scheduler import get_scheduler, add_task, start_scheduler, stop_scheduler, get_task_status
from .tasks.model_discovery import run_model_discovery, get_model_discovery_task
from .tasks.pricing_discovery import run_pricing_discovery, get_pricing_discovery_task
from .tasks.service_health_check import run_health_check_task, ServiceHealthChecker
# SiliconFlowå®šä»·ç°åœ¨ä½¿ç”¨é™æ€é…ç½®æ–‡ä»¶ (cache/siliconflow_pricing_accurate.json)
# Doubao pricing now uses static configuration (removed dynamic scraping)
from ..utils.api_key_validator import run_api_key_validation_task

logger = logging.getLogger(__name__)

class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨"""
    
    def __init__(self, config_loader=None):
        self.config_loader = config_loader
        self.scheduler = get_scheduler()
        self.is_initialized = False
    
    def initialize_tasks(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–æ‰€æœ‰å®šæ—¶ä»»åŠ¡"""
        if self.is_initialized:
            logger.warning("ä»»åŠ¡å·²åˆå§‹åŒ–ï¼Œè·³è¿‡")
            return
        
        # ä»é…ç½®ä¸­è·å–ä»»åŠ¡è®¾ç½®
        task_config = config.get('tasks', {})
        
        # 1. æ¨¡å‹å‘ç°ä»»åŠ¡ - ğŸš€ ä¿®å¤ï¼šæ­£ç¡®è¯»å–é…ç½®æ–‡ä»¶çš„ run_on_startup è®¾ç½®
        model_discovery_config = task_config.get('model_discovery', {})
        if model_discovery_config.get('enabled', True):
            interval = model_discovery_config.get('interval_hours', 6) * 3600  # è½¬æ¢ä¸ºç§’
            run_immediately = model_discovery_config.get('run_on_startup', True)  # ğŸš€ ä¿®å¤ï¼šæ¢å¤é…ç½®æ–‡ä»¶æ§åˆ¶
            
            add_task(
                name='model_discovery',
                func=self._run_model_discovery_task,
                interval_seconds=interval,
                run_immediately=run_immediately
            )
            logger.info(f"å·²æ·»åŠ æ¨¡å‹å‘ç°ä»»åŠ¡ï¼Œé—´éš” {interval/3600}h")
        
        # 2. å®šä»·å‘ç°ä»»åŠ¡
        pricing_discovery_config = task_config.get('pricing_discovery', {})
        if pricing_discovery_config.get('enabled', True):
            interval = pricing_discovery_config.get('interval_hours', 12) * 3600  # è½¬æ¢ä¸ºç§’
            run_immediately = pricing_discovery_config.get('run_on_startup', False)
            
            add_task(
                name='pricing_discovery',
                func=self._run_pricing_discovery_task,
                interval_seconds=interval,
                run_immediately=run_immediately
            )
            logger.info(f"å·²æ·»åŠ å®šä»·å‘ç°ä»»åŠ¡ï¼Œé—´éš” {interval/3600}h")
        
        # 2. APIå¯†é’¥éªŒè¯ä»»åŠ¡
        # 2. APIå¯†é’¥éªŒè¯ä»»åŠ¡ - ğŸš€ ä¿®å¤ï¼šæ­£ç¡®è¯»å–é…ç½®æ–‡ä»¶çš„ run_on_startup è®¾ç½®  
        api_key_config = task_config.get('api_key_validation', {})
        if api_key_config.get('enabled', True):
            interval = api_key_config.get('interval_hours', 6) * 3600  # è½¬æ¢ä¸ºç§’
            run_immediately = api_key_config.get('run_on_startup', True)  # ğŸš€ ä¿®å¤ï¼šæ¢å¤é…ç½®æ–‡ä»¶æ§åˆ¶
            
            add_task(
                name='api_key_validation',
                func=self._run_api_key_validation_task,
                interval_seconds=interval,
                run_immediately=run_immediately
            )
            logger.info(f"å·²æ·»åŠ APIå¯†é’¥éªŒè¯ä»»åŠ¡ï¼Œé—´éš” {interval/3600}h")
        
        # 3. å¥åº·æ£€æŸ¥ä»»åŠ¡
        health_check_config = task_config.get('health_check', {})
        if health_check_config.get('enabled', True):
            interval = health_check_config.get('interval_minutes', 30) * 60  # è½¬æ¢ä¸ºç§’
            run_immediately = health_check_config.get('run_on_startup', False)  # ä»é…ç½®æ–‡ä»¶è¯»å–
            
            add_task(
                name='health_check',
                func=self._run_health_check_task,
                interval_seconds=interval,
                run_immediately=run_immediately
            )
            logger.info(f"å·²æ·»åŠ å¥åº·æ£€æŸ¥ä»»åŠ¡ï¼Œé—´éš” {interval/60}min")
        
        # 4. ç¼“å­˜æ¸…ç†ä»»åŠ¡
        cache_cleanup_config = task_config.get('cache_cleanup', {})
        if cache_cleanup_config.get('enabled', True):
            interval = cache_cleanup_config.get('interval_hours', 24) * 3600
            
            add_task(
                name='cache_cleanup',
                func=self._run_cache_cleanup_task,
                interval_seconds=interval,
                run_immediately=False
            )
            logger.info(f"å·²æ·»åŠ ç¼“å­˜æ¸…ç†ä»»åŠ¡ï¼Œé—´éš” {interval/3600}h")
        
        # 5. SiliconFlowå®šä»· - ç°åœ¨ä½¿ç”¨é™æ€é…ç½®æ–‡ä»¶ (cache/siliconflow_pricing_accurate.json)
        # ç§»é™¤äº†åŠ¨æ€æŠ“å–ä»»åŠ¡ï¼Œæ”¹ç”¨æ‰‹åŠ¨ç»´æŠ¤çš„å‡†ç¡®ä»·æ ¼æ•°æ®
        logger.info("SiliconFlowå®šä»·ä½¿ç”¨é™æ€é…ç½®æ–‡ä»¶ï¼Œå·²ç§»é™¤åŠ¨æ€æŠ“å–ä»»åŠ¡")
        
        # 6. è±†åŒ…å®šä»· - ç°åœ¨ä½¿ç”¨é™æ€é…ç½®æ–‡ä»¶ (doubao_pricing_accurate.json)  
        # ç§»é™¤äº†åŠ¨æ€æŠ“å–ä»»åŠ¡ï¼Œæ”¹ç”¨æ‰‹åŠ¨ç»´æŠ¤çš„å‡†ç¡®ä»·æ ¼æ•°æ®
        logger.info("è±†åŒ…å®šä»·ä½¿ç”¨é™æ€é…ç½®æ–‡ä»¶ï¼Œå·²ç§»é™¤åŠ¨æ€æŠ“å–ä»»åŠ¡")
        
        # 7. ç»Ÿè®¡æŠ¥å‘Šä»»åŠ¡
        stats_config = task_config.get('stats_report', {})
        if stats_config.get('enabled', False):  # é»˜è®¤ç¦ç”¨
            interval = stats_config.get('interval_hours', 12) * 3600
            
            add_task(
                name='stats_report',
                func=self._run_stats_report_task,
                interval_seconds=interval,
                run_immediately=False
            )
            logger.info(f"å·²æ·»åŠ ç»Ÿè®¡æŠ¥å‘Šä»»åŠ¡ï¼Œé—´éš” {interval/3600}h")
        
        self.is_initialized = True
        logger.info("æ‰€æœ‰åå°ä»»åŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    async def _run_model_discovery_task(self):
        """è¿è¡Œæ¨¡å‹å‘ç°ä»»åŠ¡"""
        logger.info("å¼€å§‹æ‰§è¡Œæ¨¡å‹å‘ç°ä»»åŠ¡")
        
        try:
            if not self.config_loader or not self.config_loader.config_data:
                logger.error("é…ç½®åŠ è½½å™¨æˆ–é…ç½®æ•°æ®æœªè®¾ç½®")
                return {'success': False, 'error': 'é…ç½®åŠ è½½å™¨æˆ–é…ç½®æ•°æ®æœªè®¾ç½®'}
            
            # ç›´æ¥ä» config_data è·å–çº¯å­—å…¸ï¼Œé¿å…åºåˆ—åŒ–é—®é¢˜
            channels_data = self.config_loader.config_data.get('channels', [])
            config_data = self.config_loader.config_data
            
            # è¿è¡Œæ¨¡å‹å‘ç°
            result = await run_model_discovery(channels_data, config_data)
            
            # å¦‚æœæˆåŠŸï¼Œæ›´æ–°é…ç½®åŠ è½½å™¨çš„ç¼“å­˜
            if result.get('success'):
                discovery_task = get_model_discovery_task()
                if hasattr(self.config_loader, 'update_model_cache'):
                    self.config_loader.update_model_cache(discovery_task.cached_models)
            
            logger.info(f"æ¨¡å‹å‘ç°ä»»åŠ¡å®Œæˆ: {result}")
            return result
            
        except Exception as e:
            logger.error(f"æ¨¡å‹å‘ç°ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
            return {'success': False, 'error': str(e)}
    
    async def _run_pricing_discovery_task(self):
        """è¿è¡Œå®šä»·å‘ç°ä»»åŠ¡"""
        logger.info("å¼€å§‹æ‰§è¡Œå®šä»·å‘ç°ä»»åŠ¡")
        
        try:
            # è¿è¡Œå®šä»·å‘ç°
            result = await run_pricing_discovery()
            
            logger.info(f"å®šä»·å‘ç°ä»»åŠ¡å®Œæˆ: {result}")
            return result
            
        except Exception as e:
            logger.error(f"å®šä»·å‘ç°ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
            return {'success': False, 'error': str(e)}
    
    async def _run_api_key_validation_task(self):
        """è¿è¡ŒAPIå¯†é’¥éªŒè¯ä»»åŠ¡"""
        logger.info("å¼€å§‹æ‰§è¡ŒAPIå¯†é’¥éªŒè¯ä»»åŠ¡")
        
        try:
            if not self.config_loader or not self.config_loader.config_data:
                return {'success': False, 'error': 'é…ç½®åŠ è½½å™¨æˆ–é…ç½®æ•°æ®æœªè®¾ç½®'}
            
            # ç›´æ¥ä» config_data è·å–çº¯å­—å…¸
            channels_data = self.config_loader.config_data.get('channels', [])
            
            # è¿è¡ŒAPIå¯†é’¥éªŒè¯
            result = await run_api_key_validation_task(channels_data)
            
            stats = result.get('stats', {})
            logger.info(f"APIå¯†é’¥éªŒè¯å®Œæˆ: {stats.get('valid_keys', 0)}/{stats.get('total_keys', 0)} å¯†é’¥æœ‰æ•ˆ")
            
            return result
            
        except Exception as e:
            logger.error(f"APIå¯†é’¥éªŒè¯ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
            return {'success': False, 'error': str(e)}
    
    async def _run_health_check_task(self):
        """è¿è¡Œå¥åº·æ£€æŸ¥ä»»åŠ¡"""
        logger.info("å¼€å§‹æ‰§è¡Œå¥åº·æ£€æŸ¥ä»»åŠ¡")
        
        try:
            if not self.config_loader or not self.config_loader.config_data:
                return {'success': False, 'error': 'é…ç½®åŠ è½½å™¨æˆ–é…ç½®æ•°æ®æœªè®¾ç½®'}
            
            # ç›´æ¥ä» config_data è·å–çº¯å­—å…¸
            channels_data = self.config_loader.config_data.get('channels', [])
            
            # è·å–å·²å‘ç°çš„æ¨¡å‹æ•°æ®ï¼ˆç”¨äºé€‰æ‹©æµ‹è¯•æ¨¡å‹ï¼‰
            discovered_models = get_model_discovery_task().cached_models
            
            # è¿è¡Œå¥åº·æ£€æŸ¥
            result = await run_health_check_task(channels_data, discovered_models)
            
            stats = result.get('stats', {})
            logger.info(f"å¥åº·æ£€æŸ¥å®Œæˆ: {stats.get('healthy_channels', 0)}/{stats.get('total_channels', 0)} æ¸ é“å¥åº·")
            
            return result
            
        except Exception as e:
            logger.error(f"å¥åº·æ£€æŸ¥ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
            return {'success': False, 'error': str(e)}
    
    async def _run_cache_cleanup_task(self):
        """è¿è¡Œç¼“å­˜æ¸…ç†ä»»åŠ¡"""
        logger.info("å¼€å§‹æ‰§è¡Œç¼“å­˜æ¸…ç†ä»»åŠ¡")
        
        try:
            # æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ–‡ä»¶
            from pathlib import Path
            import time
            import os
            
            cache_dir = Path("cache")
            if not cache_dir.exists():
                return {'success': True, 'message': 'ç¼“å­˜ç›®å½•ä¸å­˜åœ¨'}
            
            # æ¸…ç†7å¤©å‰çš„æ–‡ä»¶
            cutoff_time = time.time() - (7 * 24 * 3600)
            cleaned_files = 0
            
            for file_path in cache_dir.rglob('*'):
                if file_path.is_file():
                    if file_path.stat().st_mtime < cutoff_time:
                        try:
                            os.remove(file_path)
                            cleaned_files += 1
                            logger.debug(f"åˆ é™¤è¿‡æœŸç¼“å­˜æ–‡ä»¶: {file_path}")
                        except Exception as e:
                            logger.warning(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            
            result = {
                'success': True,
                'cleaned_files': cleaned_files
            }
            
            logger.info(f"ç¼“å­˜æ¸…ç†å®Œæˆï¼Œåˆ é™¤ {cleaned_files} ä¸ªè¿‡æœŸæ–‡ä»¶")
            return result
            
        except Exception as e:
            logger.error(f"ç¼“å­˜æ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}")
            return {'success': False, 'error': str(e)}
    
    # SiliconFlowå®šä»·ä»»åŠ¡å·²ç§»é™¤ - ç°åœ¨ä½¿ç”¨é™æ€é…ç½®æ–‡ä»¶ (cache/siliconflow_pricing_accurate.json)
    
    # è±†åŒ…å®šä»·ä»»åŠ¡å·²ç§»é™¤ - ç°åœ¨ä½¿ç”¨é™æ€é…ç½®æ–‡ä»¶ (cache/doubao_pricing_accurate.json)
    
    async def _run_stats_report_task(self):
        """è¿è¡Œç»Ÿè®¡æŠ¥å‘Šä»»åŠ¡"""
        logger.info("å¼€å§‹æ‰§è¡Œç»Ÿè®¡æŠ¥å‘Šä»»åŠ¡")
        
        try:
            # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
            stats = {
                'timestamp': time.time(),
                'task_status': get_task_status(),
                'system_info': {
                    'cache_dir_size': self._get_cache_dir_size(),
                    'config_status': bool(self.config_loader)
                }
            }
            
            # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
            import json
            from pathlib import Path
            
            cache_dir = Path("cache")
            cache_dir.mkdir(exist_ok=True)
            
            stats_file = cache_dir / f"stats_report_{int(time.time())}.json"
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {stats_file}")
            return {'success': True, 'report_file': str(stats_file)}
            
        except Exception as e:
            logger.error(f"ç»Ÿè®¡æŠ¥å‘Šä»»åŠ¡å¼‚å¸¸: {e}")
            return {'success': False, 'error': str(e)}
    
    def _get_cache_dir_size(self) -> int:
        """è·å–ç¼“å­˜ç›®å½•å¤§å°"""
        try:
            from pathlib import Path
            cache_dir = Path("cache")
            if not cache_dir.exists():
                return 0
            
            total_size = 0
            for file_path in cache_dir.rglob('*'):
                if file_path.is_file():
                    total_size += file_path.stat().st_size
            
            return total_size
        except:
            return 0
    
    async def start(self):
        """å¯åŠ¨ä»»åŠ¡ç®¡ç†å™¨"""
        logger.info("å¯åŠ¨ä»»åŠ¡ç®¡ç†å™¨")
        await start_scheduler()
    
    async def stop(self):
        """åœæ­¢ä»»åŠ¡ç®¡ç†å™¨"""
        logger.info("åœæ­¢ä»»åŠ¡ç®¡ç†å™¨")
        await stop_scheduler()
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡ç®¡ç†å™¨çŠ¶æ€"""
        return {
            'initialized': self.is_initialized,
            'config_loader_set': bool(self.config_loader),
            'scheduler_status': get_task_status()
        }
    
    def set_config_loader(self, config_loader):
        """è®¾ç½®é…ç½®åŠ è½½å™¨"""
        self.config_loader = config_loader
        logger.info("é…ç½®åŠ è½½å™¨å·²è®¾ç½®")


# å…¨å±€ä»»åŠ¡ç®¡ç†å™¨å®ä¾‹
_task_manager = None

def get_task_manager() -> TaskManager:
    """è·å–å…¨å±€ä»»åŠ¡ç®¡ç†å™¨å®ä¾‹"""
    global _task_manager
    if _task_manager is None:
        _task_manager = TaskManager()
    return _task_manager


# ä¾¿æ·å‡½æ•°
async def initialize_background_tasks(config: Dict[str, Any], config_loader=None):
    """åˆå§‹åŒ–åå°ä»»åŠ¡çš„ä¾¿æ·å‡½æ•°"""
    manager = get_task_manager()
    if config_loader:
        manager.set_config_loader(config_loader)
    manager.initialize_tasks(config)
    await manager.start()
    return manager


async def stop_background_tasks():
    """åœæ­¢åå°ä»»åŠ¡çš„ä¾¿æ·å‡½æ•°"""
    manager = get_task_manager()
    await manager.stop()


def get_task_manager_status() -> Dict[str, Any]:
    """è·å–ä»»åŠ¡ç®¡ç†å™¨çŠ¶æ€çš„ä¾¿æ·å‡½æ•°"""
    manager = get_task_manager()
    return manager.get_status()