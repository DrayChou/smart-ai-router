"""
Models API endpoints
æ¨¡å‹åˆ—è¡¨APIæ¥å£
"""

import time
from typing import List, Optional

from fastapi import APIRouter
from pydantic import BaseModel

from core.json_router import JSONRouter
from core.utils.logger import get_logger
from core.yaml_config import YAMLConfigLoader
from core.services import get_model_service

from core.utils.memory_index import get_memory_index

logger = get_logger(__name__)

# --- Response Models ---

class ChannelCost(BaseModel):
    input: Optional[float] = None
    output: Optional[float] = None

class ModelCapabilities(BaseModel):
    supports_vision: bool = False
    supports_function_calling: bool = False
    supports_code_generation: bool = False
    supports_streaming: bool = False

class ChannelInfo(BaseModel):
    id: str
    name: str
    provider: Optional[str] = None
    tags: Optional[List[str]] = None
    priority: Optional[int] = None
    capabilities: Optional[List[str]] = None
    cost_per_token: Optional[ChannelCost] = None
    # æ¸ é“ç‰¹å®šçš„æ¨¡å‹ä¿¡æ¯è¦†ç›–
    channel_context_length: Optional[int] = None
    channel_capabilities: Optional[ModelCapabilities] = None
    # æ¸ é“ç‰¹å®šçš„tagsï¼ˆä»æ¸ é“é…ç½®æˆ–æ¨¡å‹åˆ†æå¾—å‡ºï¼‰
    channel_tags: Optional[List[str]] = None

class ModelInfo(BaseModel):
    id: str
    object: str = "model"
    created: int
    owned_by: str
    name: Optional[str] = None
    model_type: str = "model"
    available: bool = True
    
    # æ¨¡å‹åŸºç¡€ä¿¡æ¯
    parameter_count: Optional[int] = None  # å‚æ•°æ•°é‡(ç™¾ä¸‡)
    parameter_size_text: Optional[str] = None  # "7b", "70b"ç­‰
    context_length: Optional[int] = None  # ä¸Šä¸‹æ–‡é•¿åº¦
    context_text: Optional[str] = None  # "32k", "128k"ç­‰
    
    # æ¨¡å‹èƒ½åŠ›
    capabilities: Optional[ModelCapabilities] = None
    
    # å®šä»·ä¿¡æ¯
    input_price: Optional[float] = None
    output_price: Optional[float] = None
    
    # æ¸ é“å’Œæ ‡ç­¾ä¿¡æ¯
    channel_count: Optional[int] = None
    tags: Optional[List[str]] = None
    channels: Optional[List[ChannelInfo]] = None

class ModelsResponse(BaseModel):
    object: str = "list"
    data: List[ModelInfo]
    total_models: int = 0

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(prefix="/v1", tags=["models"])

def create_models_router(config_loader: YAMLConfigLoader, json_router: JSONRouter) -> APIRouter:
    """åˆ›å»ºæ¨¡å‹ç›¸å…³çš„APIè·¯ç”±"""

    @router.get("/models", response_model=ModelsResponse)
    async def list_models() -> ModelsResponse:
        """è¿”å›æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ï¼ŒåŒ…å«è¯¦ç»†ä¿¡æ¯"""
        model_service = get_model_service()
        all_models = set()
        model_channels_map = {}  # è®°å½•æ¨¡å‹å¯¹åº”çš„æ‰€æœ‰æ¸ é“ä¿¡æ¯

        # 1. ä»è·¯ç”±å™¨è·å–é…ç½®æ¨¡å‹
        configured_models = json_router.get_available_models()
        all_models.update(configured_models)

        # 2. ä»æ¨¡å‹å‘ç°ç¼“å­˜è·å–ç‰©ç†æ¨¡å‹å’Œå¯¹åº”çš„æ¸ é“ä¿¡æ¯
        model_cache = config_loader.get_model_cache()
        if model_cache:
            for cache_key, discovery_data in model_cache.items():
                channel_id = discovery_data.get("channel_id", cache_key)
                for model_name in discovery_data.get("models", []):
                    all_models.add(model_name)
                    # è®°å½•æ¨¡å‹å¯¹åº”çš„æ‰€æœ‰æ¸ é“ä¿¡æ¯
                    if model_name not in model_channels_map:
                        model_channels_map[model_name] = []
                    if channel_id not in model_channels_map[model_name]:
                        model_channels_map[model_name].append(channel_id)

        # 3. æ„å»ºå“åº”
        models_data = []
        current_time = int(time.time())

        # è·å–æ¸ é“æ˜ å°„å’Œå†…å­˜ç´¢å¼•ï¼ˆç”¨äºtagsæå–ï¼‰
        channels_list = config_loader.config.channels or []
        channels = {channel.id: channel for channel in channels_list}
        memory_index = get_memory_index()

        for model_id in sorted(list(all_models)):
            # è·å–æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ï¼ˆä½¿ç”¨æ–°çš„æœåŠ¡æ¶æ„ï¼‰
            base_model_info = model_service.get_model_info(model_id)
            
            # æ„å»ºåŸºç¡€èƒ½åŠ›ä¿¡æ¯
            capabilities = None
            if base_model_info and base_model_info.capabilities:
                capabilities = ModelCapabilities(
                    supports_vision=base_model_info.capabilities.supports_vision,
                    supports_function_calling=base_model_info.capabilities.supports_function_calling,
                    supports_code_generation=base_model_info.capabilities.supports_code_generation,
                    supports_streaming=base_model_info.capabilities.supports_streaming
                )

            # è·å–æ¨¡å‹æ”¯æŒçš„æ‰€æœ‰æ¸ é“
            channel_list = []
            channel_ids = model_channels_map.get(model_id, [])

            for channel_id in channel_ids:
                if channel_id in channels:
                    channel = channels[channel_id]
                    
                    # è·å–è¯¥æ¸ é“å¯¹è¯¥æ¨¡å‹çš„ç‰¹å®šä¿¡æ¯ï¼ˆå¯èƒ½åŒ…å«è¦†ç›–ï¼‰
                    channel_model_info = model_service.get_model_info(model_id, channel_id=channel_id)

                    # æ„å»ºæˆæœ¬ä¿¡æ¯ï¼ˆåº”ç”¨æ±‡ç‡æŠ˜æ‰£ï¼‰
                    cost_info = None
                    if hasattr(channel, 'cost_per_token') and channel.cost_per_token:
                        try:
                            # ä¼˜å…ˆä½¿ç”¨å¢å¼ºçš„CostEstimatorï¼ˆåŒ…å«æ±‡ç‡æŠ˜æ‰£ï¼‰
                            from core.utils.cost_estimator import CostEstimator
                            estimator = CostEstimator()
                            model_pricing = estimator._get_model_pricing(channel.id, model_id)
                            
                            if model_pricing and 'input' in model_pricing and 'output' in model_pricing:
                                cost_info = ChannelCost(
                                    input=model_pricing['input'],
                                    output=model_pricing['output']
                                )
                                logger.info(f"ğŸ’° MODELS API: Applied currency discount for {channel.id} | {model_id} | input: ${model_pricing['input']:,.6f}, output: ${model_pricing['output']:,.6f}")
                            else:
                                # å›é€€åˆ°é™æ€å®šä»·
                                cost_info = ChannelCost(
                                    input=channel.cost_per_token.get('input'),
                                    output=channel.cost_per_token.get('output')
                                )
                        except Exception as e:
                            logger.warning(f"Cost estimation failed for {channel.id}, using static pricing: {e}")
                            # å›é€€åˆ°é™æ€å®šä»·
                            cost_info = ChannelCost(
                                input=channel.cost_per_token.get('input'),
                                output=channel.cost_per_token.get('output')
                            )

                    # æ„å»ºæ¸ é“ç‰¹å®šçš„èƒ½åŠ›ä¿¡æ¯å’Œtags
                    channel_capabilities = None
                    channel_context = None
                    channel_specific_tags = [channel.id]  # è‡³å°‘åŒ…å«æ¸ é“ID
                    
                    # æ·»åŠ æ¸ é“åç§°ä½œä¸ºæ ‡ç­¾ï¼ˆå¦‚æœä¸IDä¸åŒï¼‰
                    if channel.name and channel.name.lower() != channel.id.lower():
                        channel_specific_tags.append(channel.name.lower())
                    
                    if channel_model_info:
                        if channel_model_info.capabilities:
                            channel_capabilities = ModelCapabilities(
                                supports_vision=channel_model_info.capabilities.supports_vision,
                                supports_function_calling=channel_model_info.capabilities.supports_function_calling,
                                supports_code_generation=channel_model_info.capabilities.supports_code_generation,
                                supports_streaming=channel_model_info.capabilities.supports_streaming
                            )
                        if channel_model_info.specs and channel_model_info.specs.context_length:
                            channel_context = channel_model_info.specs.context_length
                        # æ·»åŠ æ¸ é“æ¨¡å‹ç‰¹å®šçš„tagsï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                        if channel_model_info.tags:
                            channel_specific_tags.extend(channel_model_info.tags)

                    channel_list.append(ChannelInfo(
                        id=channel.id,
                        name=channel.name,
                        provider=getattr(channel, 'provider', None),
                        tags=getattr(channel, 'tags', None),
                        priority=getattr(channel, 'priority', None),
                        capabilities=getattr(channel, 'capabilities', None),
                        cost_per_token=cost_info,
                        channel_context_length=channel_context,
                        channel_capabilities=channel_capabilities,
                        channel_tags=channel_specific_tags
                    ))

            # æ„å»ºæ¨¡å‹åŸºç¡€ä¿¡æ¯
            parameter_count = None
            parameter_size_text = None
            context_length = None
            context_text = None
            input_price = None
            output_price = None
            model_tags = None

            if base_model_info:
                if base_model_info.specs:
                    parameter_count = base_model_info.specs.parameter_count
                    parameter_size_text = base_model_info.specs.parameter_size_text
                    context_length = base_model_info.specs.context_length
                    context_text = base_model_info.specs.context_text
                if base_model_info.pricing:
                    input_price = base_model_info.pricing.input_price
                    output_price = base_model_info.pricing.output_price
                if base_model_info.tags:
                    model_tags = list(base_model_info.tags)
            
            # ä»å†…å­˜ç´¢å¼•è·å–æ¨¡å‹çš„è‡ªåŠ¨æå–tagsï¼ˆå¦‚æœæ²¡æœ‰ä»base_model_infoè·å–åˆ°ï¼‰
            if not model_tags and memory_index:
                try:
                    # ä¸ä½¿ç”¨æ¸ é“çš„providerå­—æ®µï¼Œå› ä¸ºå®ƒè¡¨ç¤ºAPIåè®®å…¼å®¹æ€§è€Œéæ¨¡å‹æä¾›å•†
                    # è®©æ ‡ç­¾ç”Ÿæˆå™¨ä»æ¨¡å‹åç§°æœ¬èº«æ¨æ–­çœŸå®çš„æä¾›å•†ä¿¡æ¯
                    extracted_tags = memory_index._generate_model_tags(model_id, "")
                    if extracted_tags:
                        # è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²æ ‡ç­¾
                        model_tags = [tag for tag in extracted_tags if tag and tag.strip()]
                except Exception as e:
                    logger.debug(f"Failed to get tags for model {model_id}: {e}")
                    pass

            models_data.append(ModelInfo(
                id=model_id,
                created=current_time,
                owned_by="smart-ai-router",
                name=model_id,
                model_type="model_group" if model_id.startswith("auto:") or model_id.startswith("tag:") else "model",
                available=True,
                
                # æ¨¡å‹è¯¦ç»†ä¿¡æ¯
                parameter_count=parameter_count,
                parameter_size_text=parameter_size_text,
                context_length=context_length,
                context_text=context_text,
                capabilities=capabilities,
                input_price=input_price,
                output_price=output_price,
                tags=model_tags,
                
                # æ¸ é“ä¿¡æ¯
                channels=channel_list if channel_list else None,
                channel_count=len(channel_list) if channel_list else 0
            ))

        return ModelsResponse(data=models_data, total_models=len(models_data))

    return router
