# Smart AI Router 配置文件模板
# 复制此文件为 router_config.yaml 并填入您的API密钥

# ============================================
# 系统配置
# ============================================
system:
  name: "Smart AI Router"
  version: "0.1.0"
  description: "个人AI智能路由系统"
  storage_mode: "yaml"  # yaml, json 或 sqlite

# ============================================
# 服务器配置
# ============================================
server:
  host: "0.0.0.0"
  port: 7601
  debug: false
  cors_origins: ["*"]
  request_timeout: 300
  max_request_size: 10485760

# ============================================
# API认证配置
# ============================================
auth:
  enabled: false  # 是否启用API Token验证（可选，不设置则无需认证）
  # api_token: "your-secret-token-here"  # 取消注释并设置你的Token
  # 如果不配置api_token，系统会自动生成一个随机Token
  
  # 管理API独立认证配置
  admin:
    enabled: true  # 是否启用Admin Token验证
    # admin_token: "your-admin-secret-token-here"  # 管理接口专用Token
    # 如果不配置admin_token，系统会自动生成一个随机Admin Token

# ============================================
# Provider 配置
# ============================================
providers:
  # Burn Hair API (OpenAI兼容代理 - 便宜好用)
  burn_hair:
    name: "burn_hair"
    display_name: "Burn Hair"
    adapter_class: "OpenAIAdapter"
    base_url: "https://burn.hair"
    auth_type: "bearer"
    rate_limit: 60
    capabilities: ["text", "function_calling", "code_generation"]
    
  # Groq (超快推理速度)
  groq:
    name: "groq"
    display_name: "Groq"
    adapter_class: "OpenAIAdapter"
    base_url: "https://api.groq.com/openai"
    auth_type: "bearer"
    rate_limit: 30
    capabilities: ["text", "function_calling", "code_generation"]
    
  # SiliconFlow (硅基流动 - 国内服务商)
  siliconflow:
    name: "siliconflow"
    display_name: "SiliconFlow"
    adapter_class: "OpenAIAdapter"
    base_url: "https://api.siliconflow.cn"
    auth_type: "bearer"
    rate_limit: 60
    capabilities: ["text", "function_calling", "code_generation", "vision"]
    
  # OpenAI 官方
  openai:
    name: "openai"
    display_name: "OpenAI"
    adapter_class: "OpenAIAdapter"
    base_url: "https://api.openai.com"
    auth_type: "bearer"
    rate_limit: 60
    capabilities: ["text", "function_calling", "code_generation", "vision"]

# ============================================
# 渠道配置 (请填入您的真实API密钥)
# ============================================
channels:
  # Burn Hair 渠道 (推荐 - 性价比高)
  - id: "burn_hair_gpt4o_mini"
    name: "Burn Hair GPT-4O Mini"
    provider: "burn_hair"
    model_name: "gpt-4o-mini"
    api_key: "YOUR_BURN_HAIR_API_KEY_HERE"  # 替换为真实API密钥
    enabled: false  # 改为 true 启用
    priority: 1
    weight: 100
    tags: ["cost-effective", "gpt-4o-mini"]
    daily_limit: 1000
    cost_per_token:
      input: 0.00000015
      output: 0.0000006
    capabilities: ["text", "function_calling", "code_generation"]
    
  - id: "burn_hair_gpt4o"
    name: "Burn Hair GPT-4O"
    provider: "burn_hair"
    model_name: "gpt-4o"
    api_key: "YOUR_BURN_HAIR_API_KEY_HERE"  # 替换为真实API密钥
    enabled: false  # 改为 true 启用
    priority: 2
    weight: 80
    daily_limit: 500
    cost_per_token:
      input: 0.000002
      output: 0.000006
    capabilities: ["text", "function_calling", "code_generation", "vision"]
    
  # Groq 渠道 (推荐 - 速度最快)
  - id: "groq_llama3_8b"
    name: "Groq Llama3.1 8B"
    provider: "groq"
    model_name: "llama-3.1-8b-instant"
    api_key: "YOUR_GROQ_API_KEY_HERE"  # 替换为真实API密钥
    enabled: false  # 改为 true 启用
    priority: 1
    weight: 120
    daily_limit: 2000
    cost_per_token:
      input: 0.0000001
      output: 0.0000001
    capabilities: ["text", "function_calling", "code_generation"]
    
  - id: "groq_llama3_70b"
    name: "Groq Llama3.1 70B"
    provider: "groq"
    model_name: "llama-3.1-70b-versatile"
    api_key: "YOUR_GROQ_API_KEY_HERE"  # 替换为真实API密钥
    enabled: false  # 改为 true 启用
    priority: 2
    weight: 90
    daily_limit: 1000
    cost_per_token:
      input: 0.0000006
      output: 0.0000006
    capabilities: ["text", "function_calling", "code_generation"]
    
  # SiliconFlow 渠道 (国内访问友好)
  - id: "siliconflow_qwen"
    name: "SiliconFlow Qwen2.5"
    provider: "siliconflow"
    model_name: "Qwen/Qwen2.5-72B-Instruct"
    api_key: "YOUR_SILICONFLOW_API_KEY_HERE"  # 替换为真实API密钥
    enabled: false  # 改为 true 启用
    priority: 1
    weight: 100
    daily_limit: 1000
    cost_per_token:
      input: 0.0000001
      output: 0.0000001
    capabilities: ["text", "function_calling", "code_generation"]
    
  # OpenAI 官方渠道 (质量最高但较贵)
  - id: "openai_gpt4o_mini"
    name: "OpenAI GPT-4O Mini"
    provider: "openai"
    model_name: "gpt-4o-mini"
    api_key: "YOUR_OPENAI_API_KEY_HERE"  # 替换为真实API密钥
    enabled: false  # 改为 true 启用
    priority: 3
    weight: 60
    daily_limit: 500
    cost_per_token:
      input: 0.00000015
      output: 0.0000006
    capabilities: ["text", "function_calling", "code_generation", "vision"]

# ============================================
# 路由配置
# ============================================
routing:
  default_strategy: "cost_first"  # 优先策略: cost_first, free_first, local_first, balanced, speed_optimized, quality_optimized
  enable_fallback: true
  max_retry_attempts: 3
  health_check_interval: 300
  error_cooldown_period: 60
  
  # 模型筛选条件
  model_filters:
    min_context_length: 8192      # 最小上下文长度（tokens），设为0禁用过滤
    min_parameter_count: 0        # 最小参数数量（百万），设为0禁用过滤
    exclude_embedding_models: true  # 排除embedding模型
    exclude_vision_only_models: true  # 排除纯视觉模型
  
  # 自定义排序策略配置
  sorting_strategies:
    # 成本优先策略 (推荐默认)
    cost_first:
      - field: "cost_score"
        weight: 0.4
        order: "desc"
      - field: "parameter_score"  # 参数数量评分
        weight: 0.25
        order: "desc"
      - field: "context_score"    # 上下文长度评分
        weight: 0.2
        order: "desc"
      - field: "speed_score"
        weight: 0.15
        order: "desc"
    
    # 免费优先策略 (最大化免费资源使用)
    free_first:
      - field: "free_score"       # 免费模型优先级评分
        weight: 0.5
        order: "desc"
      - field: "cost_score"       # 成本评分
        weight: 0.3
        order: "desc"
      - field: "speed_score"      # 速度评分
        weight: 0.15
        order: "desc"
      - field: "reliability_score"  # 可靠性评分
        weight: 0.05
        order: "desc"
    
    # 本地优先策略 (最大化本地模型使用)
    local_first:
      - field: "local_score"      # 本地模型优先级评分
        weight: 0.6
        order: "desc"
      - field: "speed_score"      # 速度评分
        weight: 0.25
        order: "desc"
      - field: "cost_score"       # 成本评分
        weight: 0.1
        order: "desc"
      - field: "reliability_score"  # 可靠性评分
        weight: 0.05
        order: "desc"
    
    # 平衡策略
    balanced:
      - field: "cost_score"
        weight: 0.3
        order: "desc"
      - field: "parameter_score"
        weight: 0.25
        order: "desc"
      - field: "context_score"
        weight: 0.2
        order: "desc"
      - field: "speed_score"
        weight: 0.15
        order: "desc"
      - field: "reliability_score"
        weight: 0.1
        order: "desc"
    
    # 速度优先策略
    speed_optimized:
      - field: "speed_score"
        weight: 0.4
        order: "desc"
      - field: "cost_score"
        weight: 0.3
        order: "desc"
      - field: "parameter_score"
        weight: 0.2
        order: "desc"
      - field: "context_score"
        weight: 0.1
        order: "desc"
    
    # 质量优先策略
    quality_optimized:
      - field: "parameter_score"
        weight: 0.4
        order: "desc"
      - field: "context_score"
        weight: 0.3
        order: "desc"
      - field: "quality_score"
        weight: 0.2
        order: "desc"
      - field: "cost_score"
        weight: 0.1
        order: "desc"
  
  # 错误分类和处理策略
  error_handling:
    permanent_errors:
      - "quota_exceeded"
      - "invalid_api_key"
      - "insufficient_credits"
    temporary_errors:
      - "rate_limit_exceeded"
      - "timeout"
      - "server_error"
    cooldown_periods:
      rate_limit_exceeded: 60
      timeout: 30
      server_error: 120

# ============================================
# 缓存配置
# ============================================
caching:
  enable_response_cache: false
  cache_ttl: 3600
  max_cache_size: 1000

# ============================================
# 监控配置
# ============================================
monitoring:
  enable_metrics: true
  enable_health_checks: true
  log_level: "INFO"
  request_logging: true
  performance_tracking: true

# ============================================
# 成本控制
# ============================================
cost_control:
  global_daily_budget: 100.0
  alert_threshold: 0.8
  auto_disable_on_budget_exceeded: true
  currency: "USD"

# ============================================
# 后台任务配置
# ============================================
tasks:
  # 模型发现任务 - 自动获取各渠道的可用模型
  model_discovery:
    enabled: true
    interval_hours: 6              # 每6小时运行一次
    run_on_startup: true          # 启动时立即运行
    
  # 定价发现任务 - 自动更新模型定价信息
  pricing_discovery:
    enabled: true
    interval_hours: 12             # 每12小时运行一次
    run_on_startup: false         # 启动时不运行
    
  # 健康检查任务 - 定时检查各渠道的可用性和延迟
  health_check:
    enabled: true
    interval_minutes: 30           # 每30分钟运行一次
    run_on_startup: false         # 启动时不运行
    max_concurrent_checks: 10     # 最大并发检查数
    
  # SiliconFlow定价抓取任务 - 从官网抓取最新定价信息
  siliconflow_pricing:
    enabled: true
    interval_hours: 24             # 每24小时运行一次
    run_on_startup: true          # 启动时立即运行
    
  # 豆包定价抓取任务 - 通过Jina.ai从官网抓取模型信息和定价
  doubao_pricing:
    enabled: true
    interval_hours: 24             # 每24小时运行一次
    run_on_startup: true          # 启动时立即运行
    
  # 缓存清理任务 - 清理过期的缓存文件
  cache_cleanup:
    enabled: true
    interval_hours: 24             # 每24小时运行一次
    max_cache_age_days: 7         # 保留7天内的缓存
    
  # 统计报告任务 - 生成系统运行统计报告
  stats_report:
    enabled: false                # 默认禁用
    interval_hours: 12            # 每12小时运行一次

# ============================================
# 使用说明
# ============================================
# 1. 复制此文件为 config/router_config.yaml
# 2. 配置认证（可选但推荐）:
#    - 启用认证: 设置 auth.enabled: true
#    - 自定义Token: 取消注释 api_token 行并设置你的Token
#    - 自动生成: 留空 api_token，系统会自动生成并保存
# 3. 将所有 "YOUR_*_API_KEY_HERE" 替换为真实API密钥
# 4. 将需要启用的渠道 enabled 改为 true
# 5. 运行: python main.py
# 6. 访问: http://localhost:7601/docs 查看API文档
# 7. 测试（无认证）: 
#    curl -X POST http://localhost:7601/v1/chat/completions \
#    -H "Content-Type: application/json" \
#    -d '{"model":"tag:free","messages":[{"role":"user","content":"Hello!"}]}'
# 8. 测试（启用认证）:
#    curl -X POST http://localhost:7601/v1/chat/completions \
#    -H "Authorization: Bearer sar-your-token-here" \
#    -H "Content-Type: application/json" \
#    -d '{"model":"tag:free","messages":[{"role":"user","content":"Hello!"}]}'